% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{S3QL Documentation}
\date{October 28, 2016}
\release{2.21}
\author{Nikolaus Rath}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@kt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.60}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.53,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.47,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@cs\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.80,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.67,0.67}{\strut ##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.20,0.53}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.00}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,1.00}{\strut ##1}}}
\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.87,0.47,0.00}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.53,0.00}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.40,0.00,0.93}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.80}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.67,0.40,0.00}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.40,0.73}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.53,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.33,0.47,0.60}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.60,0.40,0.20}{##1}}}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.60,0.47,0.00}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.40,0.00,0.93}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.73,0.00,0.40}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.27,0.00,0.93}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.53,0.00}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.87}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.40,0.60}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.87,0.13,0.00}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{0.93,0.93,0.93}{\strut ##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.20,0.40}{##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.40,0.00,0.93}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.87,0.27,0.13}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.53,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.87}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.73}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}



\chapter{About S3QL}
\label{about::doc}\label{about:s3ql-user-s-guide}\label{about:about-s3ql}
S3QL is a file system that stores all its data online using storage
services like \href{http://code.google.com/apis/storage/}{Google Storage}, \href{http://aws.amazon.com/s3}{Amazon S3}, or \href{http://openstack.org/projects/storage/}{OpenStack}. S3QL
effectively provides a hard disk of dynamic, infinite capacity that
can be accessed from any computer with internet access.

S3QL is a standard conforming, full featured UNIX file system that is
conceptually indistinguishable from any local file system.
Furthermore, S3QL has additional features like compression,
encryption, data de-duplication, immutable trees and snapshotting
which make it especially suitable for online backup and archival.

S3QL is designed to favor simplicity and elegance over performance and
feature-creep. Care has been taken to make the source code as
readable and serviceable as possible. Solid error detection and error
handling have been included from the very first line, and S3QL comes
with extensive automated test cases for all its components.


\section{Features}
\label{about:openstack}\label{about:features}\begin{itemize}
\item {} 
\textbf{Transparency.} Conceptually, S3QL is indistinguishable from a
local file system. For example, it supports hardlinks, symlinks,
standard unix permissions, extended attributes and file
sizes up to 2 TB.

\item {} 
\textbf{Dynamic Size.} The size of an S3QL file system grows and shrinks
dynamically as required.

\item {} 
\textbf{Compression.} Before storage, all data may compressed with the
LZMA, bzip2 or deflate (gzip) algorithm.

\item {} 
\textbf{Encryption.} After compression (but before upload), all data can be
AES encrypted with a 256 bit key. An additional SHA256 HMAC checksum
is used to protect the data against manipulation.

\item {} 
\textbf{Data De-duplication.} If several files have identical contents,
the redundant data will be stored only once. This works across all
files stored in the file system, and also if only some parts of the
files are identical while other parts differ.

\item {} 
\textbf{Immutable Trees.} Directory trees can be made immutable, so that
their contents can no longer be changed in any way whatsoever. This
can be used to ensure that backups can not be modified after they
have been made.

\item {} 
\textbf{Copy-on-Write/Snapshotting.} S3QL can replicate entire directory
trees without using any additional storage space. Only if one of the
copies is modified, the part of the data that has been modified will
take up additional storage space. This can be used to create
intelligent snapshots that preserve the state of a directory at
different points in time using a minimum amount of space.

\item {} 
\textbf{High Performance independent of network latency.} All operations
that do not write or read file contents (like creating directories
or moving, renaming, and changing permissions of files and
directories) are very fast because they are carried out without any
network transactions.

S3QL achieves this by saving the entire file and directory structure
in a database. This database is locally cached and the remote
copy updated asynchronously.

\item {} 
\textbf{Support for low bandwidth connections.} S3QL splits file contents
into smaller blocks and caches blocks locally. This minimizes both
the number of network transactions required for reading and writing
data, and the amount of data that has to be transferred when only
parts of a file are read or written.

\end{itemize}


\section{Development Status}
\label{about:development-status}
S3QL is considered stable and suitable for production use.  Starting
with version 2.17.1, S3QL uses semantic versioning. This means that
backwards-incompatible versions (e.g., versions that require an
upgrade of the file system revision) will be reflected in an increase
of the major version number.


\section{Supported Platforms}
\label{about:supported-platforms}
S3QL is developed and tested under Linux. Users have also reported
running S3QL successfully on OS-X, FreeBSD and NetBSD. We try to
maintain compatibility with these systems, but (due to lack of
pre-release testers) we cannot guarantee that every release will run
on all non-Linux systems. Please report any bugs you find, and we will
try to fix them.


\section{Contributing}
\label{about:contributing}
The S3QL source code is available both on \href{https://github.com/s3ql/main}{GitHub} and \href{https://bitbucket.org/nikratio/s3ql/}{BitBucket}.


\chapter{Installation}
\label{installation::doc}\label{installation:installation}\label{installation:github}
S3QL depends on several other programs and libraries that have to be
installed first. The best method to satisfy these dependencies depends
on your distribution.

The following instructions are for S3QL 2.21 and should be
applicable to any system. The \href{https://bitbucket.org/nikratio/s3ql/wiki/Home}{S3QL Wiki} contains \href{https://bitbucket.org/nikratio/s3ql/wiki/Installation}{additional
help} help
for specific distributions and operating systems. Note, however, that
S3QL wiki is editable by anyone. The information there has thus not
been vetted by the S3QL maintainers, and may be wrong, out-of-date, or
even dangerous. Generally, you should only follow steps from the Wiki
that you fully understand yourself, and fall back on the instructions
below when in doubt.


\section{Dependencies}
\label{installation:dependencies}
The following is a list of the programs and libraries required for
running S3QL. Generally, you should first check if your distribution
already provides a suitable packages and only install from source if
that is not the case.
\begin{itemize}
\item {} 
Kernel: Linux 2.6.9 or newer or FreeBSD with \href{http://www.freshports.org/sysutils/fusefs-kmod/}{FUSE4BSD}. Starting with
kernel 2.6.26 you will get significantly better write performance,
so under Linux you should actually use \emph{2.6.26 or newer whenever
possible}.

\item {} 
The \href{http://psmisc.sf.net/}{psmisc} utilities.

\item {} 
\href{http://www.sqlite.org/}{SQLite} version 3.7.0 or newer. SQLite
has to be installed as a \emph{shared library} with development headers.

\item {} 
\href{http://www.python.org/}{Python} 3.3.0 or newer. Make sure to also
install the development headers.

\item {} 
The following Python modules:
\begin{itemize}
\item {} 
\href{https://pypi.python.org/pypi/setuptools}{setuptools}, version 1.0 or newer.

\item {} 
\href{https://www.dlitz.net/software/pycrypto/}{pycrypto}

\item {} 
\href{https://pypi.python.org/pypi/defusedxml/}{defusedxml}

\item {} 
\href{https://pypi.python.org/pypi/requests/}{requests} (optional,
required for OAuth2 authentication with Google Storage)

\item {} 
\href{https://github.com/systemd/python-systemd}{systemd} (optional,
for enabling systemd support).

\item {} 
\href{https://github.com/rogerbinns/apsw}{apsw}, version 3.7.0 or
newer.

\item {} 
\href{https://bitbucket.org/nikratio/python-llfuse/}{llfuse}, any
version between 1.0 (inclusive) and 2.0 (exclusive)

\item {} 
\href{https://bitbucket.org/nikratio/python-dugong/}{dugong}, any
version between 3.4 (inclusive) and 4.0 (exclusive)

\item {} 
\href{http://pytest.org/}{pytest}, version 2.3.3 or newer (optional, to run unit tests)

\item {} 
\href{https://github.com/eisensheng/pytest-catchlog}{pytest-catchlog}
(optional, to run unit tests)

\end{itemize}

To check if a specific module \code{\textless{}module\textgreater{}} is installed, execute
\code{python3 -c 'import \emph{\textless{}module\textgreater{}};
print(\emph{\textless{}module\textgreater{}}.\_\_version\_\_)'}. This will result in an
\code{ImportError} if the module is not installed, and will print the
installed version if the module is installed.

\end{itemize}


\section{Installing S3QL}
\label{installation:inst-s3ql}\label{installation:installing-s3ql}
To build and install S3QL itself, proceed as follows:
\begin{enumerate}
\item {} 
Download S3QL from \href{https://bitbucket.org/nikratio/s3ql/downloads}{https://bitbucket.org/nikratio/s3ql/downloads}

\item {} 
Unpack it into a folder of your choice

\item {} 
Run \code{python3 setup.py build\_ext -{-}inplace} to build S3QL.

\item {} 
Run \code{python3 -m pytest tests/} to run a self-test. If this fails, ask
for help on the \href{http://groups.google.com/group/s3ql}{mailing list} or report a bug in the
\href{https://bitbucket.org/nikratio/s3ql/issues}{issue tracker}.

\end{enumerate}

Now you have three options:
\begin{itemize}
\item {} 
You can run the S3QL commands from the \code{bin/} directory.

\item {} 
You can install S3QL system-wide for all users. To do that, you
have to run \code{sudo python3 setup.py install}.

\item {} 
You can install S3QL into \code{\textasciitilde{}/.local} by executing \code{python3
setup.py install -{-}user}. In this case you should make sure that
\code{\textasciitilde{}/.local/bin} is in your \code{\$PATH} environment variable.

\end{itemize}


\section{Development Version}
\label{installation:development-version}
If you have checked out the unstable development version from the
Mercurial repository, a bit more effort is required. You'll also need:
\begin{itemize}
\item {} 
Version 0.24 or newer of the \href{http://www.cython.org/}{Cython} compiler.

\item {} 
Version 1.2b1 or newer of the \href{http://sphinx.pocoo.org/}{Sphinx} document processor.

\end{itemize}

With these additional dependencies installed, S3QL can be build and
tested with

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{python3 setup.py build\PYGZus{}cython}
\PYG{l}{python3 setup.py build\PYGZus{}ext \PYGZhy{}\PYGZhy{}inplace}
\PYG{l}{python3 \PYGZhy{}m pytest tests/}
\end{Verbatim}

Note that when building from the Mercurial or Git repository, building
and testing is done with several additional checks. This may cause
compilation and/or tests to fail even though there are no problems
with functionality. For example, any use of functions that are
scheduled for deprecation in future Python version will cause tests to
fail. If you would rather just check for functionality, you can delete
the \code{MANIFEST.in} file. In that case, the build system will
behave as it does for a regular release.

The HTML and PDF documentation can be generated with

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{python3 setup.py build\PYGZus{}sphinx}
\end{Verbatim}

and S3QL can be installed as usual with

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{python3 setup.py install }\PYG{g+ge}{[\PYGZhy{}\PYGZhy{}user]}
\end{Verbatim}


\section{Running tests requiring remote servers}
\label{installation:running-tests-requiring-remote-servers}
By default, tests requiring a connection to a remote storage backend
are skipped. If you would like to run these tests too (which is always
a good idea), you have to create additional entries in your
\code{\textasciitilde{}/.s3ql/authinfo2} file that tell S3QL what server and credentials to
use for these tests. These entries have the following form:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+ge}{[\PYGZlt{}BACKEND\PYGZgt{}\PYGZhy{}test]}
\PYG{l}{backend\PYGZhy{}login: }\PYG{n+nv}{\PYGZlt{}user\PYGZgt{}}
\PYG{l}{backend\PYGZhy{}password: }\PYG{n+nv}{\PYGZlt{}password\PYGZgt{}}
\PYG{l}{test\PYGZhy{}fs: }\PYG{n+nv}{\PYGZlt{}storage\PYGZhy{}url\PYGZgt{}}
\end{Verbatim}

Here \emph{\textless{}BACKEND\textgreater{}} specifies the backend that you want to test
(e.g. \emph{s3}, \emph{s3c}, \emph{gs}, or \emph{swift}), \emph{\textless{}user\textgreater{}} and \emph{\textless{}password\textgreater{}} are
the backend authentication credentials, and \emph{\textless{}storage-url\textgreater{}} specifies
the full storage URL that will be used for testing. \textbf{Any existing
S3QL file system in this storage URL will be destroyed during
testing}.

For example, to run tests that need connection to a Google Storage
server, you would add something like

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+ge}{[gs\PYGZhy{}test]}
\PYG{l}{backend\PYGZhy{}login: GOOGIGWLONT238MD7HZ4}
\PYG{l}{backend\PYGZhy{}password: rmEbstjscoeunt1249oes1298gauidbs3hl}
\PYG{l}{test\PYGZhy{}fs: gs://joes\PYGZhy{}gs\PYGZhy{}bucket/s3ql\PYGZus{}tests/}
\end{Verbatim}

On the next run of \code{runtest.py} (or \code{py.test} when using the
development version), the additional tests will be run. If the tests
are still skipped, you can get more information about why tests are
being skipped by passing the \code{-rs} argument to
\code{runtest.py}/\code{py.test}.


\chapter{Storage Backends}
\label{backends::doc}\label{backends:storage-backends}\label{backends:id1}\label{backends:sphinx}
S3QL supports different \emph{backends} to store data at different service
providers and using different protocols. A \emph{storage url} specifies a
backend together with some backend-specific information and uniquely
identifies an S3QL file system. The form of the storage url depends on
the backend and is described for every backend below.

Furthermore, every S3QL commands that accepts a storage url also
accepts a \code{-{-}backend-options} parameter than can be used to
pass backend-specific options to the backend module. The available
options are documented with the respective backends below.

All storage backends respect the \code{http\_proxy} (for plain HTTP
connections) and \code{https\_proxy} (for SSL connections)
environment variables.

\begin{notice}{note}{Note:}
Storage backends are not necessarily compatible. Don't expect that
you can e.g. copy the data stored by the local backend into Amazon
S3 using some non-S3QL tool and then access it with S3QL's S3
backend. If you want to copy file systems from one backend to
another, you need to use the \code{clone\_fs.py} script (from the
\code{contrib} directory in the S3QL tarball).
\end{notice}


\section{Google Storage}
\label{backends:google-storage}
\href{http://code.google.com/apis/storage/}{Google Storage} is an online
storage service offered by Google. To use the Google Storage backend,
you need to have (or sign up for) a Google account, and then \href{http://code.google.com/apis/storage/docs/signup.html}{activate
Google Storage}
for your account. The account is free, you will pay only for the
amount of storage and traffic that you actually use. There are two
ways to access Google storage:
\begin{enumerate}
\item {} 
Use S3-like authentication. To do this, first \href{https://developers.google.com/storage/docs/migrating\#defaultproj}{set a  default
project}.
Then use the \href{https://code.google.com/apis/console/\#:storage:legacy}{key management tool} to
retrieve your \emph{Google Storage developer access key} and \emph{Google
Storage developer secret} and use that as backend login and backend
password.

\item {} 
Use OAuth2 authentication. In this case you need to use \code{oauth2}
as the backend login, and a valid OAuth2 refresh token as the
backend password. To obtain a refresh token, you can use the
{\hyperref[man/oauth_client:oauth-client]{\emph{s3ql\_oauth\_client}}} program. It will instruct
you to open a specific URL in your browser, enter a code and
authenticate with your Google account. Once this procedure is
complete, {\hyperref[man/oauth_client:oauth-client]{\emph{s3ql\_oauth\_client}}} will print out
the refresh token. Note that you need to do this procedure only
once, the refresh token will remain valid until you explicitly
revoke it.

\end{enumerate}

To create a Google Storage bucket, you can use e.g. the \href{https://sandbox.google.com/storage/}{Google
Storage Manager}. The storage URL for accessing the bucket in S3QL is
then

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{gs://}\PYG{n+nv}{\PYGZlt{}bucketname\PYGZgt{}}\PYG{l}{/}\PYG{n+nv}{\PYGZlt{}prefix\PYGZgt{}}
\end{Verbatim}

Here \emph{bucketname} is the name of the bucket, and \emph{prefix} can be an
arbitrary prefix that will be prepended to all object names used by
S3QL. This allows you to store several S3QL file systems in the same
Google Storage bucket.

The Google Storage backend accepts the following backend options:
\index{gs\_backend command line option!no-ssl}\index{no-ssl!gs\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-gs_backend-arg-no-ssl}\pysigline{\bfcode{no-ssl}\code{}}
Disable encrypted (https) connections and use plain HTTP instead.

\end{fulllineitems}

\index{gs\_backend command line option!ssl-ca-path=\textless{}path\textgreater{}}\index{ssl-ca-path=\textless{}path\textgreater{}!gs\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-gs_backend-arg-ssl-ca-path}\pysigline{\bfcode{ssl-ca-path}\code{=\textless{}path\textgreater{}}}
Instead of using the system's default certificate store, validate
the server certificate against the specified CA
certificates. \code{\textless{}path\textgreater{}} may be either a file containing
multiple certificates, or a directory containing one certificate
per file.

\end{fulllineitems}

\index{gs\_backend command line option!tcp-timeout}\index{tcp-timeout!gs\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-gs_backend-arg-tcp-timeout}\pysigline{\bfcode{tcp-timeout}\code{}}
Specifies the timeout used for TCP connections. If no data can be
exchanged with the remote server for longer than this period, the
TCP connection is closed and re-established (default: 20 seconds).

\end{fulllineitems}



\section{Amazon S3}
\label{backends:amazon-s3}\label{backends:google-storage-manager}
\href{http://aws.amazon.com/s3}{Amazon S3} is the online storage service
offered by \href{http://aws.amazon.com/}{Amazon Web Services (AWS)}. To
use the S3 backend, you first need to sign up for an AWS account. The
account is free, you will pay only for the amount of storage and
traffic that you actually use. After that, you need to create a bucket
that will hold the S3QL file system, e.g. using the \href{https://console.aws.amazon.com/s3/home}{AWS Management
Console}. For best
performance, it is recommend to create the bucket in the
geographically closest storage region, but not the US Standard region
(see {\hyperref[durability:durability]{\emph{Important Rules to Avoid Losing Data}}} for the reason).

The storage URL for accessing S3 buckets in S3QL has the form

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3://}\PYG{n+nv}{\PYGZlt{}bucketname\PYGZgt{}}\PYG{l}{/}\PYG{n+nv}{\PYGZlt{}prefix\PYGZgt{}}
\end{Verbatim}

Here \emph{bucketname} is the name of the bucket, and \emph{prefix} can be an
arbitrary prefix that will be prepended to all object names used by
S3QL. This allows you to store several S3QL file systems in the same
S3 bucket.

Note that the backend login and password for accessing S3 are not the
user id and password that you use to log into the Amazon Webpage, but
the \emph{AWS access key id} and \emph{AWS secret access key} shown under \href{https://aws-portal.amazon.com/gp/aws/developer/account/index.html?ie=UTF8\&action=access-key}{My
Account/Access Identifiers}.

The Amazon S3 backend accepts the following backend options:
\index{s3\_backend command line option!no-ssl}\index{no-ssl!s3\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3_backend-arg-no-ssl}\pysigline{\bfcode{no-ssl}\code{}}
Disable encrypted (https) connections and use plain HTTP instead.

\end{fulllineitems}

\index{s3\_backend command line option!ssl-ca-path=\textless{}path\textgreater{}}\index{ssl-ca-path=\textless{}path\textgreater{}!s3\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3_backend-arg-ssl-ca-path}\pysigline{\bfcode{ssl-ca-path}\code{=\textless{}path\textgreater{}}}
Instead of using the system's default certificate store, validate
the server certificate against the specified CA
certificates. \code{\textless{}path\textgreater{}} may be either a file containing
multiple certificates, or a directory containing one certificate
per file.

\end{fulllineitems}

\index{s3\_backend command line option!tcp-timeout}\index{tcp-timeout!s3\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3_backend-arg-tcp-timeout}\pysigline{\bfcode{tcp-timeout}\code{}}
Specifies the timeout used for TCP connections. If no data can be
exchanged with the remote server for longer than this period, the
TCP connection is closed and re-established (default: 20 seconds).

\end{fulllineitems}

\index{s3\_backend command line option!sse}\index{sse!s3\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3_backend-arg-sse}\pysigline{\bfcode{sse}\code{}}
Enable server side encryption. Both costs \& benefits of S3 server
side encryption are probably rather small, and this option does
\emph{not} affect any client side encryption performed by S3QL itself.

\end{fulllineitems}

\index{s3\_backend command line option!ia}\index{ia!s3\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3_backend-arg-ia}\pysigline{\bfcode{ia}\code{}}
Use infrequent access storage class for new objects.

\end{fulllineitems}

\index{s3\_backend command line option!rrs}\index{rrs!s3\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3_backend-arg-rrs}\pysigline{\bfcode{rrs}\code{}}
Enable reduced redundancy storage for newly created objects
(overwrites the \emph{ia} option).

When enabling this option, it is strongly recommended to
periodically run {\hyperref[fsck:s3ql-verify]{\emph{s3ql\_verify}}}, because objects
that are lost by the storage backend may cause subsequent data loss
even later in time due to the data de-duplication feature of S3QL (see
{\hyperref[durability:backend-reliability]{\emph{Data Durability}}} for details).

\end{fulllineitems}



\section{OpenStack/Swift}
\label{backends:openstack-swift}\label{backends:openstack-backend}
\href{http://www.openstack.org/}{OpenStack} is an open-source cloud server application suite. \href{http://openstack.org/projects/storage/}{Swift} is
the cloud storage module of OpenStack. Swift/OpenStack storage is
offered by many different companies.

There are two different storage URL for the OpenStack backend that
make use of different authentication APIs. For legacy (v1)
authentication, the storage URL is

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{swift://}\PYG{n+nv}{\PYGZlt{}hostname\PYGZgt{}}\PYG{g+ge}{[:\PYGZlt{}port\PYGZgt{}]}\PYG{l}{/}\PYG{n+nv}{\PYGZlt{}container\PYGZgt{}}\PYG{g+ge}{[/\PYGZlt{}prefix\PYGZgt{}]}
\end{Verbatim}

for keystore (v2) authentication, the storage URL is

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{swiftks://}\PYG{n+nv}{\PYGZlt{}hostname\PYGZgt{}}\PYG{g+ge}{[:\PYGZlt{}port\PYGZgt{}]}\PYG{l}{/}\PYG{n+nv}{\PYGZlt{}region\PYGZgt{}}\PYG{l}{:}\PYG{n+nv}{\PYGZlt{}container\PYGZgt{}}\PYG{g+ge}{[/\PYGZlt{}prefix\PYGZgt{}]}
\end{Verbatim}

Note that when using keystore authentication, you can (and have to)
specify the storage region of the container as well.

In both cases, \emph{hostname} name should be the name of the
authentication server.  The storage container must already exist (most
OpenStack providers offer either a web frontend or a command line tool
for creating containers). \emph{prefix} can be an arbitrary prefix that
will be prepended to all object names used by S3QL, which can be used
to store multiple S3QL file systems in the same container.

When using legacy authentication, the backend login and password
correspond to the OpenStack username and API Access Key. When using
keystore authentication, the backend password is your regular
OpenStack password and the backend login combines you OpenStack
username and tenant name in the form \code{\textless{}tenant\textgreater{}:\textless{}user\textgreater{}}. If no tenant
is required, the OpenStack username alone may be used as backend
login.

The OpenStack backend accepts the following backend options:
\index{swift\_backend command line option!no-ssl}\index{no-ssl!swift\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-swift_backend-arg-no-ssl}\pysigline{\bfcode{no-ssl}\code{}}
Use plain HTTP to connect to the authentication server. This option
does not directly affect the connection to the storage
server. Whether HTTPS or plain HTTP is used to connect to the
storage server is determined by the authentication server.

\end{fulllineitems}

\index{swift\_backend command line option!ssl-ca-path=\textless{}path\textgreater{}}\index{ssl-ca-path=\textless{}path\textgreater{}!swift\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-swift_backend-arg-ssl-ca-path}\pysigline{\bfcode{ssl-ca-path}\code{=\textless{}path\textgreater{}}}
Instead of using the system's default certificate store, validate
the server certificate against the specified CA
certificates. \code{\textless{}path\textgreater{}} may be either a file containing
multiple certificates, or a directory containing one certificate
per file.

\end{fulllineitems}

\index{swift\_backend command line option!tcp-timeout}\index{tcp-timeout!swift\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-swift_backend-arg-tcp-timeout}\pysigline{\bfcode{tcp-timeout}\code{}}
Specifies the timeout used for TCP connections. If no data can be
exchanged with the remote server for longer than this period, the
TCP connection is closed and re-established (default: 20 seconds).

\end{fulllineitems}

\index{swift\_backend command line option!disable-expect100}\index{disable-expect100!swift\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-swift_backend-arg-disable-expect100}\pysigline{\bfcode{disable-expect100}\code{}}
If this option is specified, S3QL does not use the \code{Expect:
continue} header (cf. \href{http://tools.ietf.org/html/rfc2616\#section-8.2.3}{RFC2616, section 8.2.3}) when uploading
data to the server. This can be used to work around broken storage
servers that don't fully support HTTP 1.1, but may decrease
performance as object data will be transmitted to the server more
than once in some circumstances.

\end{fulllineitems}



\section{Rackspace CloudFiles}
\label{backends:swift}\label{backends:rackspace-cloudfiles}
\href{http://www.rackspace.com/}{Rackspace} CloudFiles uses \href{http://www.openstack.org/}{OpenStack} internally, so it is possible to
just use the OpenStack/Swift backend (see above) with
\code{auth.api.rackspacecloud.com} as the host name. For convenince,
there is also a special \code{rackspace} backend that uses a storage URL
of the form

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{rackspace://}\PYG{n+nv}{\PYGZlt{}region\PYGZgt{}}\PYG{l}{/}\PYG{n+nv}{\PYGZlt{}container\PYGZgt{}}\PYG{g+ge}{[/\PYGZlt{}prefix\PYGZgt{}]}
\end{Verbatim}

The storage container must already exist in the selected
region. \emph{prefix} can be an arbitrary prefix that will be prepended to
all object names used by S3QL and can be used to store several S3QL
file systems in the same container.

You can create a storage container for S3QL using the \href{https://mycloud.rackspace.com/}{Cloud Control
Panel} (click on \emph{Files} in the
topmost menu bar).

The Rackspace backend accepts the same backend options as the
{\hyperref[backends:openstack-backend]{\emph{OpenStack backend}}}.

\begin{notice}{note}{Note:}
As of January 2012, Rackspace does not give any durability or
consistency guarantees (see {\hyperref[durability:durability]{\emph{Important Rules to Avoid Losing Data}}} for why this is
important).  However, Rackspace support agents seem prone to claim
very high guarantees.  Unless explicitly backed by their terms of
service, any such statement should thus be viewed with
suspicion. S3QL developers have also \href{http://www.rath.org/Tales\%20from\%20the\%20Rackspace\%20Support}{repeatedly experienced}
similar issues with the credibility and competence of the Rackspace
support.
\end{notice}


\section{S3 compatible}
\label{backends:rackspace}\label{backends:s3-compatible}
The S3 compatible backend allows S3QL to access any storage service
that uses the same protocol as Amazon S3. The storage URL has the form

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3c://}\PYG{n+nv}{\PYGZlt{}hostname\PYGZgt{}}\PYG{l}{:}\PYG{n+nv}{\PYGZlt{}port\PYGZgt{}}\PYG{l}{/}\PYG{n+nv}{\PYGZlt{}bucketname\PYGZgt{}}\PYG{l}{/}\PYG{n+nv}{\PYGZlt{}prefix\PYGZgt{}}
\end{Verbatim}

Here \emph{bucketname} is the name of an (existing) bucket, and \emph{prefix}
can be an arbitrary prefix that will be prepended to all object names
used by S3QL. This allows you to store several S3QL file systems in
the same bucket.

The S3 compatible backend accepts the following backend options:
\index{s3c\_backend command line option!no-ssl}\index{no-ssl!s3c\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3c_backend-arg-no-ssl}\pysigline{\bfcode{no-ssl}\code{}}
Disable encrypted (https) connections and use plain HTTP instead.

\end{fulllineitems}

\index{s3c\_backend command line option!ssl-ca-path=\textless{}path\textgreater{}}\index{ssl-ca-path=\textless{}path\textgreater{}!s3c\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3c_backend-arg-ssl-ca-path}\pysigline{\bfcode{ssl-ca-path}\code{=\textless{}path\textgreater{}}}
Instead of using the system's default certificate store, validate
the server certificate against the specified CA
certificates. \code{\textless{}path\textgreater{}} may be either a file containing
multiple certificates, or a directory containing one certificate
per file.

\end{fulllineitems}

\index{s3c\_backend command line option!tcp-timeout}\index{tcp-timeout!s3c\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3c_backend-arg-tcp-timeout}\pysigline{\bfcode{tcp-timeout}\code{}}
Specifies the timeout used for TCP connections. If no data can be
exchanged with the remote server for longer than this period, the
TCP connection is closed and re-established (default: 20 seconds).

\end{fulllineitems}

\index{s3c\_backend command line option!disable-expect100}\index{disable-expect100!s3c\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3c_backend-arg-disable-expect100}\pysigline{\bfcode{disable-expect100}\code{}}
If this option is specified, S3QL does not use the \code{Expect:
continue} header (cf. \href{http://tools.ietf.org/html/rfc2616\#section-8.2.3}{RFC2616, section 8.2.3}) when uploading
data to the server. This can be used to work around broken storage
servers that don't fully support HTTP 1.1, but may decrease
performance as object data will be transmitted to the server more
than once in some circumstances.

\end{fulllineitems}

\index{s3c\_backend command line option!dumb-copy}\index{dumb-copy!s3c\_backend command line option}

\begin{fulllineitems}
\phantomsection\label{backends:cmdoption-s3c_backend-arg-dumb-copy}\pysigline{\bfcode{dumb-copy}\code{}}
If this option is specified, S3QL assumes that a COPY request to
the storage server has succeeded as soon as the server returns a
\code{200 OK} status. The \href{http://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectCOPY.html}{S3 COPY API} specifies that the
storage server may still return an error in the request body (see
the \href{https://doc.s3.amazonaws.com/proposals/copy.html}{copy proposal} for the rationale), so this
option should only be used if you are certain that your storage
server only returns \code{200 OK} when the copy operation has been
completely and successfully carried out. Using this option may be
neccessary if your storage server does not return a valid response
body for a succesfull copy operation.

\end{fulllineitems}



\section{Local}
\label{backends:id6}\label{backends:local}
S3QL is also able to store its data on the local file system. This can
be used to backup data on external media, or to access external
services that S3QL can not talk to directly (e.g., it is possible to
store data over SSH by first mounting the remote system using \href{http://fuse.sourceforge.net/sshfs.html}{sshfs}
and then using the local backend to store the data in the sshfs
mountpoint).

The storage URL for local storage is

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{local://}\PYG{n+nv}{\PYGZlt{}path\PYGZgt{}}
\end{Verbatim}

Note that you have to write three consecutive slashes to specify an
absolute path, e.g. \code{local:///var/archive}. Also, relative paths will
automatically be converted to absolute paths before the authentication
file (see {\hyperref[authinfo:authinfo]{\emph{Storing Authentication Information}}}) is read, i.e. if you are in the
\code{/home/john} directory and try to mount \code{local://s3ql}, the
corresponding section in the authentication file must match the
storage url \code{local:///home/john/s3ql}.

The local backend does not accept any backend options.


\chapter{Important Rules to Avoid Losing Data}
\label{durability::doc}\label{durability:sshfs}\label{durability:durability}\label{durability:important-rules-to-avoid-losing-data}
Most S3QL backends store data in distributed storage systems. These
systems differ from a traditional, local hard disk in several
important ways. In order to avoid losing data, this section should be
read very carefully.


\section{Rules in a Nutshell}
\label{durability:rules-in-a-nutshell}
To avoid losing your data, obey the following rules:
\begin{enumerate}
\item {} 
Know what durability you can expect from your chosen storage
provider. The durability describes how likely it is that a stored
object becomes damaged over time. Such data corruption can never be
prevented completely, techniques like geographic replication and
RAID storage just reduce the likelihood of it to happen (i.e.,
increase the durability).

\item {} 
When choosing a backend and storage provider, keep in mind that
when using S3QL, the effective durability of the file system data
will be reduced because of S3QL's data de-duplication feature.

\item {} 
Determine your storage service's consistency window. The
consistency window that is important for S3QL is the smaller of the
times for which:
\begin{itemize}
\item {} 
a newly created object may not yet be included in the list of
stored objects

\item {} 
an attempt to read a newly created object may fail with the
storage service reporting that the object does not exist

\end{itemize}

If \emph{one} of the above times is zero, we say that as far as S3QL is
concerned the storage service has \emph{immediate} consistency.

If your storage provider claims that \emph{neither} of the above can
ever happen, while at the same time promising high durability, you
should choose a respectable provider instead.

\item {} 
When mounting the same file system on different computers (or on
the same computer but with different \code{-{-}cachedir} directories),
the time that passes between the first and second of invocation of
\textbf{mount.s3ql} must be at least as long as your storage
service's consistency window. If your storage service offers
immediate consistency, you do not need to wait at all.

\item {} 
Before running \textbf{fsck.s3ql} or \textbf{s3qladm}, the file system
must have been left untouched for the length of the consistency
window. If your storage service offers immediate consistency, you
do not need to wait at all.

\end{enumerate}

The rest of this section explains the above rules and the reasons for
them in more detail. It also contains a list of the consistency
windows for a number of larger storage providers.


\section{Consistency Window List}
\label{durability:consistency-window-list}
The following is a list of the consistency windows (as far as S3QL is
concerned) for a number of storage providers. This list doesn't come
with any guarantees and may be outdated. If your storage provider is
not included, or if you need more reliable information, check with
your storage provider.

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textsf{\relax 
Storage Provider
} & \textsf{\relax 
Consistency Window
}\\
\hline
Amazon S3 in the US standard region
 & 
No guarantees
\\
\hline
Amazon S3 in other regions
 & 
Immediate
\\
\hline
Google Storage
 & 
Immediate
\\
\hline\end{tabulary}



\section{Data Consistency}
\label{durability:data-consistency}
In contrast to the typical hard disk, most storage providers do not
guarantee \emph{immediate consistency} of written data. This means that:
\begin{itemize}
\item {} 
after an object has been stored, requests to read this object may
still fail or return the prior contents for a little while.

\item {} 
after an object has been deleted, attempts to read it may still
return the (old) data for some time, and it may still remain in the
list of stored objects for some time.

\item {} 
after a new object has been created, it may still not be included
when retrieving the list of stored objects for some time.

\end{itemize}

Of course, none of this is acceptable for a file system, and S3QL
generally handles any of the above situations internally so that it
always provides a fully consistent file system to the user. However,
there are some situations where an S3QL user nevertheless needs to be
aware of the peculiarities of his chosen storage service.

Suppose that you mount the file system, store some new data, delete
some old data and unmount it. If you then mount the file system again
right away on another computer, there is no guarantee that S3QL will
see any of the changes that the first S3QL process has made. At least
in theory it is therefore possible that on the second mount, S3QL does
not see any of the changes that you have done and presents you an ``old
version'' of the file system without them. Even worse, if you notice
the problem and unmount the file system, S3QL will upload the old
status (which S3QL necessarily has to consider as current) and thereby
permanently override the newer version (even though this change may
not become immediately visible either). S3QL uses several techniques
to reduce the likelihood of this to happen (see {\hyperref[impl_details:impl-details]{\emph{Implementation Details}}}
for more information on this), but without support from the storage
service, the possibility cannot be eliminated completely.

The same problem of course also applies when checking the file system.
If the storage service provides S3QL with only partially updated data,
S3QL has no way to find out if this a real consistency problem that
needs to be fixed or if it is only a temporary problem that will
resolve itself automatically (because there are still changes that
have not become visible yet).

This is where the so called \emph{consistency window} comes in. The
consistency window is the maximum time (after writing or deleting the
object) for which any of the above ``outdated responses'' may be
received. If the consistency window is zero, i.e. all changes are
immediately effective, the storage service is said to have \emph{immediate
consistency}. If the window is infinite, i.e. there is no upper bound
on the time it may take for changes to become effect, the storage
service is said to be \emph{eventually consistent}. Note that often there
are different consistency windows for the different operations. For
example, Google Storage offers immediate consistency when reading
data, but only eventual consistency for the list of stored objects.

To prevent the problem of S3QL working with an outdated copy of the
file system data, it is therefore sufficient to simply wait for the
consistency window to pass before mounting the file system again (or
running a file system check). The length of the consistency window
changes from storage service to storage service, and if your service
is not included in the list below, you should check the web page or
ask the technical support of your storage provider. The window that is
important for S3QL is the smaller of the times for which
\begin{itemize}
\item {} 
a newly created object may not yet be included in the list of
stored objects

\item {} 
an attempt to read a newly created object may fail with the
storage service reporting that the object does not exist

\end{itemize}

Unfortunately, many storage providers are hesitant to guarantee
anything but eventual consistency, i.e. the length of the consistency
window is potentially infinite. In that case you simply have to pick a
length that you consider ``safe enough''. For example, even though
Amazon is only guaranteeing eventual consistency, the ordinary
consistency window for data stored in S3 is just a few seconds, and
only in exceptional circumstances (i.e., core network outages) it may
rise up to hours (\href{http://forums.aws.amazon.com/message.jspa?messageID=38471\#38471}{source}).


\section{Data Durability}
\label{durability:backend-reliability}\label{durability:data-durability}
The durability of a storage service a measure of the average
probability of a storage object to become corrupted over time. The
lower the chance of data loss, the higher the durability. Storage
services like Amazon S3 claim to achieve a durability of up to
99.999999999\% over a year, i.e. if you store 100000000 objects for 100
years, you can expect that at the end of that time one object will be
corrupted or lost.

S3QL is designed to reduce redundancy and store data in the smallest
possible form. Therefore, S3QL is generally not able to compensate for
any such losses, and when choosing a storage service you should
carefully review if the offered durability matches your requirements.
When doing this, there are two factors that should be kept in mind.

Firstly, even though S3QL is not able to compensate for storage
service failures, it is able to detect them: when trying to access
data that has been lost or corrupted by the storage service, an IO
error will be returned and the mount point will become inaccessible to
ensure that the problem is noticed.

Secondly, the consequences of a data loss by the storage service can
be significantly more severe than you may expect because of S3QL's
data de-duplication feature: a data loss in the storage service at
time \emph{x} may cause data that is written \emph{after} time \emph{x} to be lost as
well. Consider the following scenario:
\begin{enumerate}
\item {} 
You store an important file in the S3QL file system.

\item {} 
The storage service loses the data blocks of this file. As long as you
do not access the file or run \textbf{fsck.s3ql}, S3QL is not
aware that the data has been lost by the storage service.

\item {} 
You save an additional copy of the important file in a different
location on the same S3QL file system.

\item {} 
S3QL detects that the contents of the new file are identical to the
data blocks that have been stored earlier. Since at this point S3QL
is not aware that these blocks have been lost by the storage service, it
does not save another copy of the file contents in the storage service but
relies on the (presumably) existing blocks instead.

\item {} 
Therefore, even though you saved another copy, you still do not
have a backup of the important file (since both copies refer to the
same data blocks that have been lost by the storage service).

\end{enumerate}

For some storage services, \textbf{fsck.s3ql} can mitigate this
effect. When \textbf{fsck.s3ql} runs, it asks the storage service
for a list of all stored objects. If objects are missing, it can then
mark the damaged files and prevent the problem from spreading forwards
in time. Figuratively speaking, this establishes a ``checkpoint'': data
loss that occurred before running \textbf{fsck.s3ql} can not affect
any file system operations that are performed after the check.
Unfortunately, many storage services only ``discover'' that objects are
missing or broken when the object actually needs to be retrieved. In
this case, \textbf{fsck.s3ql} will not learn anything by just
querying the list of objects.

This effect can be mitigated to some degree by using the
\textbf{s3ql\_verify} command in additon to
\textbf{fsck.s3ql}. \textbf{s3ql\_verify} asks the storage service
to look up every stored object and may therefore take much longer than
running \textbf{fsck.s3ql}, but can also offer a much stronger
assurance that no data has been lost by the storage service. To
``recover'' from damaged storage objects in the backend, the damaged
objects found by \textbf{s3ql\_verify} have to be explicitly deleted
(so that a successive \textbf{fsck.s3ql} is able detect them as
missing, correct the file system metadata, and move any affected files
to \code{lost+found}). This procedure is currently not automated, so
it is generally a good idea to choose a storage service where the
expected data durability is high enough so that the possibility of a
lost object (and thus the need to run any full checks) can be
neglected over long periods of time.


\chapter{File System Creation}
\label{mkfs::doc}\label{mkfs:file-system-creation}
A S3QL file system is created with the \textbf{mkfs.s3ql} command. It has the
following syntax:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{mkfs.s3ql }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}

This command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}version]  
just print program version and exit
\item [-L \textless{}name\textgreater{}]  
Filesystem label
\item [-{-}max-obj-size \textless{}size\textgreater{}]  
Maximum size of storage objects in KiB. Files bigger
than this will be spread over multiple objects in the
storage backend. Default: 10240 KiB.
\item [-{-}plain]  
Create unencrypted file system.
\item [-{-}force]  
Overwrite any existing data.
\end{optionlist}
\end{quote}

Unless you have specified the \code{-{-}plain} option,
\textbf{mkfs.s3ql} will ask you to enter an encryption
password. This password will \emph{not} be read from an authentication file
specified with the \code{-{-}authfile} option to prevent accidental
creation of an encrypted file system.

Note that:
\begin{itemize}
\item {} 
All data that is stored under the given storage url is assumed to
managed exclusively by S3QL. Trying to manually save additional
objects (or remove or manipulate existing objects) will lead to file
system corruption, and \textbf{fsck.s3ql} may delete objects that
do not belong to the file system.

\item {} 
With most storage backends, slashes in the storage url prefix do not
have special meaning. For example, the storage urls
\code{s3://mybucket/myprefix/} and \code{s3://mybucket/myprefix} are
distinct. In the first case, the prefix is \code{myprefix/}, while in
the second it is \code{myprefix}.

\item {} 
S3QL file systems can not be ``stacked'', i.e. you cannot have one
file system stored at \code{s3://bucketname/outerprefix} and a second
one at \code{s3://bucketname/outerprefix/innerprefix}.

\end{itemize}


\chapter{Managing File Systems}
\label{adm::doc}\label{adm:managing-file-systems}
The \code{s3qladm} command performs various operations on \emph{unmounted} S3QL
file systems. The file system \emph{must not be mounted} when using
\code{s3qladm} or things will go wrong badly.

The syntax is

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qladm }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}action\PYGZgt{}}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage\PYGZhy{}url\PYGZgt{}}
\end{Verbatim}

where \code{action} may be either of \textbf{passphrase},
\textbf{upgrade}, \textbf{clear} or \textbf{download-metadata}.

The \textbf{s3qladm} accepts the following general options, no
matter what specific action is being invoked:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}log \textless{}target\textgreater{}]  
Destination for log messages. Specify \code{none} for
standard output or \code{syslog} for the system logging
daemon. Anything else will be interpreted as a file
name. Log files will be rotated when they reach 1 MiB,
and at most 5 old log files will be kept. Default:
\code{None}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}version]  
just print program version and exit
\end{optionlist}
\end{quote}

Hint: run \code{s3qladm \textless{}action\textgreater{} -{-}help} to get help on the additional arguments
that the different actions take.


\section{Changing the Passphrase}
\label{adm:changing-the-passphrase}
To change the passphrase of a file system, use the \code{passphrase}
subcommand:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qladm passphrase  }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}


\section{Upgrading the file system}
\label{adm:upgrading-the-file-system}
If you have installed a new version of S3QL, it may sometimes be
necessary to upgrade the file system metadata as well. Note that in
this case the file system can no longer be accessed with older
versions of S3QL after the upgrade.

During the upgrade you have to make sure that the command is not
interrupted, and that no one else tries to mount, check or upgrade the
file system at the same time.

To upgrade a file system from the previous to the current revision,
execute

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qladm upgrade }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}


\section{Deleting a file system}
\label{adm:deleting-a-file-system}
A file system can be deleted with:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qladm clear }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}

This physically deletes all the data and file system structures.


\section{Restoring Metadata Backups}
\label{adm:restoring-metadata-backups}
If the most-recent copy of the file system metadata has been damaged
irreparably, it is possible to restore one of the automatically
created backup copies.

The command

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qladm download\PYGZhy{}metadata }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}

will give you a list of the available metadata backups and allow you
to download them. This will create two new files in the current
directory, ending in \code{.db} and \code{.params}. To actually use the
downloaded backup, you need to move these files into the \code{\textasciitilde{}/.s3ql/}
directory and run \code{fsck.s3ql}.

\begin{notice}{warning}{Warning:}
You should probably not use this functionality without having asked
for help on the mailing list first (see {\hyperref[resources:resources]{\emph{Further Resources / Getting Help}}}).
\end{notice}


\chapter{Mounting}
\label{mount::doc}\label{mount:mounting}
A S3QL file system is mounted with the \textbf{mount.s3ql}
command. It has the following syntax:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{mount.s3ql }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}mountpoint\PYGZgt{}}
\end{Verbatim}

\begin{notice}{note}{Note:}
S3QL is not a network file system like \href{http://en.wikipedia.org/wiki/Network\_File\_System\_\%28protocol\%29}{NFS}
or \href{http://en.wikipedia.org/wiki/CIFS}{CIFS}. It can only be
mounted on one computer at a time.
\end{notice}

This command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}log \textless{}target\textgreater{}]  
Destination for log messages. Specify \code{none} for
standard output or \code{syslog} for the system logging
daemon. Anything else will be interpreted as a file
name. Log files will be rotated when they reach 1 MiB,
and at most 5 old log files will be kept. Default:
\code{\textasciitilde{}/.s3ql/mount.log}
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}version]  
just print program version and exit
\item [-{-}cachesize \textless{}size\textgreater{}]  
Cache size in KiB (default: autodetect).
\item [-{-}max-cache-entries \textless{}num\textgreater{}]  
Maximum number of entries in cache (default:
autodetect). Each cache entry requires one file
descriptor, so if you increase this number you have to
make sure that your process file descriptor limit (as
set with \code{ulimit -n}) is high enough (at least the
number of cache entries + 100).
\item [-{-}allow-other]  
Normally, only the user who called \code{mount.s3ql} can
access the mount point. This user then also has full
access to it, independent of individual file
permissions. If the \code{-{-}allow-other} option is
specified, other users can access the mount point as
well and individual file permissions are taken into
account for all users.
\item [-{-}allow-root]  
Like \code{-{-}allow-other}, but restrict access to the
mounting user and the root user.
\item [-{-}fg]  
Do not daemonize, stay in foreground
\item [-{-}upstart]  
Stay in foreground and raise SIGSTOP once mountpoint
is up.
\item [-{-}compress \textless{}algorithm-lvl\textgreater{}]  
Compression algorithm and compression level to use
when storing new data. \emph{algorithm} may be any of
\code{lzma}, \code{bzip2}, \code{zlib}, or none. \emph{lvl} may be any
integer from 0 (fastest) to 9 (slowest). Default:
\code{lzma-6}
\item [-{-}metadata-upload-interval \textless{}seconds\textgreater{}]  
Interval in seconds between complete metadata uploads.
Set to 0 to disable. Default: 24h.
\item [-{-}threads \textless{}no\textgreater{}]  
Number of parallel upload threads to use (default:
auto).
\item [-{-}nfs]  
Enable some optimizations for exporting the file
system over NFS. (default: False)
\end{optionlist}
\end{quote}


\section{Permission Checking}
\label{mount:permission-checking}
If the file system is mounted with neither the \code{allow-root}
nor \code{allow-other} option, the mounting user has full
permissions on the S3QL file system (he is effectively root). If one
(or both) of the options is used, standard unix permission checks
apply, i.e. only the real root user has full access and all other
users (including the mounting user) are subject to permission checks.


\section{Compression Algorithms}
\label{mount:compression-algorithms}
S3QL supports three compression algorithms, LZMA, Bzip2 and zlib (with
LZMA being the default). The compression algorithm can be specified
freely whenever the file system is mounted, since it affects only the
compression of new data blocks.

Roughly speaking, LZMA is slower but achieves better compression
ratios than Bzip2, while Bzip2 in turn is slower but achieves better
compression ratios than zlib.

For maximum file system performance, the best algorithm therefore
depends on your network connection speed: the compression algorithm
should be fast enough to saturate your network connection.

To find the optimal algorithm and number of parallel compression
threads for your system, S3QL ships with a program called
\code{benchmark.py} in the \code{contrib} directory. You should run this program
on a file that has a size that is roughly equal to the block size of
your file system and has similar contents. It will then determine the
compression speeds for the different algorithms and the upload speeds
for the specified backend and recommend the best algorithm that is
fast enough to saturate your network connection.

Obviously you should make sure that there is little other system load
when you run \code{benchmark.py} (i.e., don't compile software or encode
videos at the same time).


\section{Notes about Caching}
\label{mount:notes-about-caching}
S3QL maintains a local cache of the file system data to speed up
access. The cache is block based, so it is possible that only parts of
a file are in the cache.


\subsection{Maximum Number of Cache Entries}
\label{mount:maximum-number-of-cache-entries}
The maximum size of the cache can be configured with the
\code{-{-}cachesize} option. In addition to that, the maximum number
of objects in the cache is limited by the
\code{-{-}max-cache-entries} option, so it is possible that the cache
does not grow up to the maximum cache size because the maximum number
of cache elements has been reached. The reason for this limit is that
each cache entry requires one open file descriptor, and Linux
distributions usually limit the total number of file descriptors per
process to about a thousand.

If you specify a value for \code{-{-}max-cache-entries}, you should
therefore make sure to also configure your system to increase the
maximum number of open file handles. This can be done temporarily with
the \textbf{ulimit -n} command. The method to permanently change this limit
system-wide depends on your distribution.


\subsection{Cache Flushing and Expiration}
\label{mount:cache-flushing-and-expiration}
S3QL flushes changed blocks in the cache to the backend whenever a block
has not been accessed for at least 10 seconds. Note that when a block is
flushed, it still remains in the cache.

Cache expiration (i.e., removal of blocks from the cache) is only done
when the maximum cache size is reached. S3QL always expires the least
recently used blocks first.


\section{Failure Modes}
\label{mount:failure-modes}
Once an S3QL file system has been mounted, there is a multitude of
problems that can occur when communicating with the remote
server. Generally, \textbf{mount.s3ql} always tries to keep the file
system as accessible as possible under the circumstances. That means
that if network connectivity is lost, data can still be written as
long as there is space in the local cache. Attempts to read data not
already present in the cache, however, will block until connection is
re-established. If any sort of data corruption is detected, the file
system will switch to read-only mode. Attempting to read files that
are affected by the corruption will return an input/output error
(\emph{errno} set to \code{EIO}).

In case of other unexpected or fatal problems, \textbf{mount.s3ql}
terminates, but does not unmount the file system. Any attempt to
access the mountpoint will result in a ``Transport endpoint not
connected'' error (\emph{errno} set to \code{ESHUTDOWN}). This ensures that a
mountpoint whose \textbf{mount.s3ql} process has terminated can not
be confused with a mountpoint containing an empty file system (which
would be fatal if e.g. the mountpoint is automatically mirrored). When
this has happened, the mountpoint can be cleared by using the
\textbf{fusermount} command (provided by FUSE) with the \code{-u}
parameter.

\textbf{mount.s3ql} will automatically try to re-establish the
connection to the server if network connectivity is lost, and retry
sending a request when the connection is established but the remote
server signals a temporary problem. These attempts will be made at
increasing intervals for a period up to 24 hours, with retry intervals
starting at 20 ms and increasing up to 5 minutes. After 24 hours,
\textbf{mount.s3ql} will give up and terminate, leaving the
mountpoint inaccessible as described above.

Generally, \textbf{mount.s3ql} will also emit log messages for any
unusual conditions that it encounters. The destination for these
messages can be set with the \code{-{-}log} parameter. It is highly
recommended to periodically check these logs, for example with a tool
like \href{http://sourceforge.net/projects/logcheck/}{logcheck}. Many potential issues that \textbf{mount.s3ql} may
encounter do not justify restricting access to the file system, but
should nevertheless be investigated if they occur. Checking the log
messages is the only way to find out about them.


\section{Automatic Mounting}
\label{mount:logcheck}\label{mount:automatic-mounting}
If you want to mount and umount an S3QL file system automatically at
system startup and shutdown, you should do so with a dedicated S3QL
init job (instead of using \code{/etc/fstab}. When using systemd,
\textbf{mount.s3ql} can be run as a service of type \code{notify}.

\begin{notice}{note}{Note:}
In principle, it is also possible to automatically mount an S3QL
file system with an appropriate entry in \code{/etc/fstab}. However,
this is not recommended for several reasons:
\begin{itemize}
\item {} 
file systems mounted in \code{/etc/fstab} will be unmounted with the
\textbf{umount} command, so your system will not wait until all data has
been uploaded but shutdown (or restart) immediately (this is a
FUSE limitation, see \href{https://bitbucket.org/nikratio/s3ql/issue/1/blocking-fusermount-and-umount}{issue \#1}).

\item {} 
There is no way to tell the system that mounting S3QL requires a
Python interpreter to be available, so it may attempt to run
\textbf{mount.s3ql} before it has mounted the volume containing
the Python interpreter.

\item {} 
There is no standard way to tell the system that internet
connection has to be up before the S3QL file system can be
mounted.

\end{itemize}
\end{notice}


\chapter{Advanced S3QL Features}
\label{special::doc}\label{special:advanced-s3ql-features}

\section{Snapshotting and Copy-on-Write}
\label{special:s3qlcp}\label{special:snapshotting-and-copy-on-write}
The command \code{s3qlcp} can be used to duplicate a directory tree without
physically copying the file contents. This is made possible by the
data de-duplication feature of S3QL.

The syntax of \code{s3qlcp} is:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qlcp }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}src\PYGZgt{}}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}target\PYGZgt{}}
\end{Verbatim}

This will replicate the contents of the directory \code{\textless{}src\textgreater{}} in the
directory \code{\textless{}target\textgreater{}}. \code{\textless{}src\textgreater{}} has to be an existing directory and
\code{\textless{}target\textgreater{}} must not exist. Moreover, both directories have to be
within the same S3QL file system.

The replication will not take any additional space. Only if one of
directories is modified later on, the modified data will take
additional storage space.

\code{s3qlcp} can only be called by the user that mounted the file system
and (if the file system was mounted with \code{-{-}allow-other} or \code{-{-}allow-root})
the root user.

Note that:
\begin{itemize}
\item {} 
After the replication, both source and target directory will still
be completely ordinary directories. You can regard \code{\textless{}src\textgreater{}} as a
snapshot of \code{\textless{}target\textgreater{}} or vice versa. However, the most common
usage of \code{s3qlcp} is to regularly duplicate the same source
directory, say \code{documents}, to different target directories. For a
e.g. monthly replication, the target directories would typically be
named something like \code{documents\_January} for the replication in
January, \code{documents\_February} for the replication in February etc.
In this case it is clear that the target directories should be
regarded as snapshots of the source directory.

\item {} 
Exactly the same effect could be achieved by an ordinary copy
program like \code{cp -a}. However, this procedure would be orders of
magnitude slower, because \code{cp} would have to read every file
completely (so that S3QL had to fetch all the data over the network
from the backend) before writing them into the destination folder.

\end{itemize}


\subsection{Snapshotting vs Hardlinking}
\label{special:snapshotting-vs-hardlinking}
Snapshot support in S3QL is inspired by the hardlinking feature that
is offered by programs like \href{http://www.samba.org/rsync}{rsync} or
\href{http://savannah.nongnu.org/projects/storebackup}{storeBackup}.
These programs can create a hardlink instead of copying a file if an
identical file already exists in the backup. However, using hardlinks
has two large disadvantages:
\begin{itemize}
\item {} 
backups and restores always have to be made with a special program
that takes care of the hardlinking. The backup must not be touched
by any other programs (they may make changes that inadvertently
affect other hardlinked files)

\item {} 
special care needs to be taken to handle files which are already
hardlinked (the restore program needs to know that the hardlink was
not just introduced by the backup program to safe space)

\end{itemize}

S3QL snapshots do not have these problems, and they can be used with
any backup program.


\section{Getting Statistics}
\label{special:s3qlstat}\label{special:getting-statistics}
You can get more information about a mounted S3QL file system with the
\code{s3qlstat} command. It has the following syntax:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qlstat }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}mountpoint\PYGZgt{}}
\end{Verbatim}

This will print out something like this

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{Directory entries:    1488068}
\PYG{l}{Inodes:               1482991}
\PYG{l}{Data blocks:          87948}
\PYG{l}{Total data size:      400 GiB}
\PYG{l}{After de\PYGZhy{}duplication: 51 GiB (12.98\PYGZpc{} of total)}
\PYG{l}{After compression:    43 GiB (10.85\PYGZpc{} of total, 83.60\PYGZpc{} of de\PYGZhy{}duplicated)}
\PYG{l}{Database size:        172 MiB (uncompressed)}
\PYG{l}{(some values do not take into account not\PYGZhy{}yet\PYGZhy{}uploaded dirty blocks in cache)}
\end{Verbatim}

Probably the most interesting numbers are the total size of your data,
the total size after duplication, and the final size after
de-duplication and compression.

\code{s3qlstat} can only be called by the user that mounted the file system
and (if the file system was mounted with \code{-{-}allow-other} or \code{-{-}allow-root})
the root user.

For a full list of available options, run \code{s3qlstat -{-}help}.


\section{Immutable Trees}
\label{special:s3qllock}\label{special:immutable-trees}
The command \textbf{s3qllock} can be used to make a directory tree
immutable. Immutable trees can no longer be changed in any way
whatsoever. You can not add new files or directories and you can not
change or delete existing files and directories. The only way to get
rid of an immutable tree is to use the \textbf{s3qlrm} command (see
below).

For example, to make the directory tree beneath the directory
\code{2010-04-21} immutable, execute

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qllock 2010\PYGZhy{}04\PYGZhy{}21}
\end{Verbatim}

Immutability is a feature designed for backups. Traditionally, backups
have been made on external tape drives. Once a backup was made, the
tape drive was removed and locked somewhere in a shelf. This has the
great advantage that the contents of the backup are now permanently
fixed. Nothing (short of physical destruction) can change or delete
files in the backup.

In contrast, when backing up into an online storage system like S3QL,
all backups are available every time the file system is mounted.
Nothing prevents a file in an old backup from being changed again
later on. In the worst case, this may make your entire backup system
worthless. Imagine that your system gets infected by a nasty virus
that simply deletes all files it can find -- if the virus is active
while the backup file system is mounted, the virus will destroy all
your old backups as well!

Even if the possibility of a malicious virus or trojan horse is
excluded, being able to change a backup after it has been made is
generally not a good idea. A common S3QL use case is to keep the file
system mounted at all times and periodically create backups with
\textbf{rsync -a}. This allows every user to recover her files from a
backup without having to call the system administrator. However, this
also allows every user to accidentally change or delete files \emph{in} one
of the old backups.

Making a backup immutable protects you against all these problems.
Unless you happen to run into a virus that was specifically programmed
to attack S3QL file systems, backups can be neither deleted nor
changed after they have been made immutable.


\section{Fast Recursive Removal}
\label{special:s3qlrm}\label{special:fast-recursive-removal}
The \code{s3qlrm} command can be used to recursively delete files and
directories on an S3QL file system. Although \code{s3qlrm} is faster than
using e.g. \code{rm -r}, the main reason for its existence is that it
allows you to delete immutable trees as well. The syntax is rather
simple:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qlrm }\PYG{n+nv}{\PYGZlt{}directory\PYGZgt{}}
\end{Verbatim}

Be warned that there is no additional confirmation. The directory will
be removed entirely and immediately.


\section{Runtime Configuration}
\label{special:runtime-configuration}\label{special:s3qlctrl}
The \code{s3qlctrl} can be used to control a mounted S3QL file system. Its
syntax is

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qlctrl }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}action\PYGZgt{}}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}mountpoint\PYGZgt{}}\PYG{l}{ ...}
\end{Verbatim}

\code{\textless{}mountpoint\textgreater{}} must be the location of a mounted S3QL file system.
For a list of valid options, run \code{s3qlctrl -{-}help}. \code{\textless{}action\textgreater{}}
may be either of:
\begin{quote}
\begin{quote}\begin{description}
\item[{flushcache}] \leavevmode
Flush file system cache. The command blocks until the cache has
been flushed.

\item[{log}] \leavevmode
Change log level.

\item[{cachesize}] \leavevmode
Change file system cache size.

\item[{upload-meta}] \leavevmode
Trigger a metadata upload.

\end{description}\end{quote}
\end{quote}


\chapter{Unmounting}
\label{umount::doc}\label{umount:unmounting}
To unmount an S3QL file system, use the command:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{umount.s3ql }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}mountpoint\PYGZgt{}}
\end{Verbatim}

This will block until all data has been written to the backend.

Only the user who mounted the file system with \textbf{mount.s3ql}
is able to unmount it again. If you are root and want to unmount an
S3QL file system mounted by an ordinary user, you have to use the
\textbf{fusermount -u} or \textbf{umount} command instead. Note
that these commands do not block until all data has been uploaded, so
if you use them instead of \code{umount.s3ql} then you should manually wait
for the \code{mount.s3ql} process to terminate before shutting down the
system.

The \textbf{umount.s3ql} command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\item [-{-}lazy, -z]  
Lazy umount. Detaches the file system immediately,
even if there are still open files. The data will be
uploaded in the background once all open files have
been closed.
\end{optionlist}
\end{quote}

If, for some reason, the \code{umount.sql} command does not work, the file
system can also be unmounted with \code{fusermount -u -z}. Note that this
command will return immediately and the file system may continue to
upload data in the background for a while longer.


\chapter{Checking for Errors}
\label{fsck::doc}\label{fsck:checking-for-errors}
It is recommended to periodically run the \textbf{fsck.s3ql} and
\textbf{s3ql\_verify} commands (in this order) to ensure that the
file system is consistent, and that there has been no data corruption
or data loss in the storage backend.

\textbf{fsck.s3ql} is intended to detect and correct problems with
the internal file system structure, caused by e.g. a file system crash
or a bug in S3QL. It assumes that the storage backend can be fully
trusted, i.e. if the backend reports that a specific storage object
exists, \textbf{fsck.s3ql} takes that as proof that the data is
present and intact.

In contrast to that, the \textbf{s3ql\_verify} command is intended to
check the consistency of the storage backend. It assumes that the
internal file system data is correct, and verifies that all data can
actually be retrieved from the backend. Running \textbf{s3ql\_verify}
may therefore take much longer than running \textbf{fsck.s3ql}.


\section{Checking and repairing internal file system errors}
\label{fsck:checking-and-repairing-internal-file-system-errors}
\textbf{fsck.s3ql} checks that the internal file system structure is
consistent and attempts to correct any problems it finds. If an S3QL
file system has not been unmounted correcly for any reason, you need
to run \textbf{fsck.s3ql} before you can mount the file system
again.

The \textbf{fsck.s3ql} command has the following syntax:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{fsck.s3ql }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}

This command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}log \textless{}target\textgreater{}]  
Destination for log messages. Specify \code{none} for
standard output or \code{syslog} for the system logging
daemon. Anything else will be interpreted as a file
name. Log files will be rotated when they reach 1 MiB,
and at most 5 old log files will be kept. Default:
\code{\textasciitilde{}/.s3ql/fsck.log}
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}version]  
just print program version and exit
\item [-{-}batch]  
If user input is required, exit without prompting.
\item [-{-}force]  
Force checking even if file system is marked clean.
\end{optionlist}
\end{quote}


\section{Detecting and handling backend data corruption}
\label{fsck:detecting-and-handling-backend-data-corruption}\label{fsck:s3ql-verify}
The \textbf{s3ql\_verify} command verifies all data in the file
system.  In contrast to \textbf{fsck.s3ql}, \textbf{s3ql\_verify}
does not trust the object listing returned by the backend, but
actually attempts to retrieve every object. By default,
\textbf{s3ql\_verify} will attempt to retrieve just the metadata for
every object (for e.g. the S3-compatible or Google Storage backends
this corresponds to a \code{HEAD} request for each object), which is
generally sufficient to determine if the object still exists. When
specifying the \code{-{-}data} option, \textbf{s3ql\_verify} will
instead read every object entirely. To determine how much data will be
transmitted in total when using \code{-{-}data}, look at the \emph{After
compression} row in the {\hyperref[special:s3qlstat]{\emph{s3qlstat}}} output.

\textbf{s3ql\_verify} is not able to correct any data corruption that
it finds. Instead, a list of the corrupted and/or missing objects is
written to a file and the decision about the proper course of action
is left to the user. If you have administrative access to the backend
server, you may want to investigate the cause of the corruption or
check if the missing/corrupted objects can be restored from
backups. If you believe that the missing/corrupted objects are indeed
lost irrevocably, you can use the {\hyperref[contrib:remove-objects]{\emph{remove\_objects.py}}} script (from
the \code{contrib} directory of the S3QL distribution) to explicitly
delete the objects from the storage backend. After that, you should
run \textbf{fsck.s3ql}. Since the (now explicitly deleted) objects
should now no longer be included in the object index reported by the
backend, \textbf{fsck.s3ql} will identify the objects as missing,
update the internal file system structures accordingly, and move the
affected files into the \code{lost+found} directory.

The \textbf{s3ql\_verify} command has the following syntax:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3ql\PYGZus{}verify }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}

This command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}missing-file \textless{}name\textgreater{}]  
File to store keys of missing objects.
\item [-{-}corrupted-file \textless{}name\textgreater{}]  
File to store keys of corrupted objects.
\item [-{-}data]  
Read every object completely, instead of checking just
the metadata.
\item [-{-}parallel PARALLEL]  
Number of connections to use in parallel.
\item [-{-}start-with \textless{}n\textgreater{}]  
Skip over first \textless{}n\textgreater{} objects and with verifying object
\textless{}n\textgreater{}+1.
\end{optionlist}
\end{quote}


\chapter{Storing Authentication Information}
\label{authinfo::doc}\label{authinfo:authinfo}\label{authinfo:storing-authentication-information}
Normally, S3QL reads username and password for the backend as well as
an encryption passphrase for the file system from the terminal. Most
commands also accept an \code{-{-}authfile} parameter that can be
used to read this information from a file instead.

The authentication file consists of sections, led by a \code{{[}section{]}}
header and followed by \code{name: value} entries. The section headers
themselves are not used by S3QL but have to be unique within the file.

In each section, the following entries can be defined:
\begin{quote}\begin{description}
\item[{storage-url}] \leavevmode
Specifies the storage url to which this section applies. If a
storage url starts with the value of this entry, the section is
considered applicable.

\item[{backend-login}] \leavevmode
Specifies the username to use for authentication with the backend.

\item[{backend-password}] \leavevmode
Specifies the password to use for authentication with the backend.

\item[{fs-passphrase}] \leavevmode
Specifies the passphrase to use to decrypt the file system (if
it is encrypted).

\end{description}\end{quote}

When reading the authentication file, S3QL considers every applicable
section in order and uses the last value that it found for each entry.
For example, consider the following authentication file:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+ge}{[s3]}
\PYG{l}{storage\PYGZhy{}url: s3://}
\PYG{l}{backend\PYGZhy{}login: joe}
\PYG{l}{backend\PYGZhy{}password: notquitesecret}

\PYG{g+ge}{[fs1]}
\PYG{l}{storage\PYGZhy{}url: s3://joes\PYGZhy{}first\PYGZhy{}bucket}
\PYG{l}{fs\PYGZhy{}passphrase: neitheristhis}

\PYG{g+ge}{[fs2]}
\PYG{l}{storage\PYGZhy{}url: s3://joes\PYGZhy{}second\PYGZhy{}bucket}
\PYG{l}{fs\PYGZhy{}passphrase: swordfish}

\PYG{g+ge}{[fs3]}
\PYG{l}{storage\PYGZhy{}url: s3://joes\PYGZhy{}second\PYGZhy{}bucket/with\PYGZhy{}prefix}
\PYG{l}{backend\PYGZhy{}login: bill}
\PYG{l}{backend\PYGZhy{}password: bi23ll}
\PYG{l}{fs\PYGZhy{}passphrase: ll23bi}
\end{Verbatim}

With this authentication file, S3QL would try to log in as ``joe''
whenever the s3 backend is used, except when accessing a storage url
that begins with ``s3://joes-second-bucket/with-prefix''. In that case,
the last section becomes active and S3QL would use the ``bill''
credentials. Furthermore, file system encryption passphrases will be used
for storage urls that start with ``s3://joes-first-bucket'' or
``s3://joes-second-bucket''.

The authentication file is parsed by the \href{http://docs.python.org/library/configparser.html}{Python ConfigParser
module}.


\chapter{Contributed Programs}
\label{contrib::doc}\label{contrib:contributed-programs}
S3QL comes with a few contributed programs that are not part of the
core distribution (and are therefore not installed automatically by
default), but which may nevertheless be useful. These programs are in
the \code{contrib} directory of the source distribution or in
\code{/usr/share/doc/s3ql/contrib} if you installed S3QL from a package.


\section{benchmark.py}
\label{contrib:benchmark-py}
This program measures S3QL write performance, uplink bandwidth and
compression speed to determine the limiting factor. It also gives
recommendation for compression algorithm and number of upload threads
to achieve maximum performance.


\section{clone\_fs.py}
\label{contrib:clone-fs-py}
This program physically clones an S3QL file system from one backend
into another, without recompressing or reencrypting.  It can be used to
migrate S3 buckets to a different storage region or storage class
(standard or reduced redundancy).


\section{pcp.py}
\label{contrib:pcp}\label{contrib:pcp-py}
\code{pcp.py} is a wrapper program that starts several rsync processes to
copy directory trees in parallel. This is important because
transferring files in parallel significantly enhances performance when
copying data from an S3QL file system (see {\hyperref[tips:copy-performance]{\emph{Improving copy performance}}} for
details).

To recursively copy the directory \code{/mnt/home-backup} into
\code{/home/joe} using 8 parallel processes and preserving permissions,
you would execute

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{pcp.py \PYGZhy{}a \PYGZhy{}\PYGZhy{}processes=8 /mnt/home\PYGZhy{}backup/ /home/joe}
\end{Verbatim}


\section{s3ql\_backup.sh}
\label{contrib:s3ql-backup-sh}
This is an example script that demonstrates how to set up a simple but
powerful backup solution using S3QL and \href{http://samba.org/rsync}{rsync}.

The \code{s3ql\_backup.sh} script automates the following steps:
\begin{enumerate}
\item {} 
Mount the file system

\item {} 
Replicate the previous backup with {\hyperref[special:s3qlcp]{\emph{s3qlcp}}}

\item {} 
Update the new copy with the data from the backup source using rsync

\item {} 
Make the new backup immutable with {\hyperref[special:s3qllock]{\emph{s3qllock}}}

\item {} 
Delete old backups that are no longer needed

\item {} 
Unmount the file system

\end{enumerate}

The backups are stored in directories of the form
\code{YYYY-MM-DD\_HH:mm:SS} and the {\hyperref[contrib:expire-backups-py]{expire\_backups.py}} command is used to
delete old backups.


\section{expire\_backups.py}
\label{contrib:expire-backups-py}
\textbf{expire\_backups.py} is a program to intelligently remove old
backups that are no longer needed.

To define what backups you want to keep for how long, you define a
number of \emph{age ranges}. \textbf{expire\_backups} ensures that you
will have at least one backup in each age range at all times. It will
keep exactly as many backups as are required for that and delete any
backups that become redundant.

Age ranges are specified by giving a list of range boundaries in terms
of backup cycles. Every time you create a new backup, the existing
backups age by one cycle.

Example: when \textbf{expire\_backups} is called with the age range
definition \code{1 3 7 14 31}, it will guarantee that you always have the
following backups available:
\begin{enumerate}
\item {} 
A backup that is 0 to 1 cycles old (i.e, the most recent backup)

\item {} 
A backup that is 1 to 3 cycles old

\item {} 
A backup that is 3 to 7 cycles old

\item {} 
A backup that is 7 to 14 cycles old

\item {} 
A backup that is 14 to 31 cycles old

\end{enumerate}

\begin{notice}{note}{Note:}
If you do backups in fixed intervals, then one cycle will be
equivalent to the backup interval. The advantage of specifying the
age ranges in terms of backup cycles rather than days or weeks is
that it allows you to gracefully handle irregular backup intervals.
Imagine that for some reason you do not turn on your computer for
one month. Now all your backups are at least a month old, and if you
had specified the above backup strategy in terms of absolute ages,
they would all be deleted! Specifying age ranges in terms of backup
cycles avoids these sort of problems.
\end{notice}

\textbf{expire\_backups} usage is simple. It requires backups to be
stored in directories of the form \code{year-month-day\_hour:minute:seconds}
(\code{YYYY-MM-DD\_HH:mm:ss}) and works on all backups in the current
directory. So for the above backup strategy, the correct invocation
would be:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{expire\PYGZus{}backups.py 1 3 7 14 31}
\end{Verbatim}

When storing your backups on an S3QL file system, you probably want to
specify the \code{-{-}use-s3qlrm} option as well. This tells
\textbf{expire\_backups} to use the {\hyperref[special:s3qlrm]{\emph{s3qlrm}}} command to
delete directories.

\textbf{expire\_backups} uses a ``state file'' to keep track which
backups are how many cycles old (since this cannot be inferred from
the dates contained in the directory names). The standard name for
this state file is \code{.expire\_backups.dat}. If this file gets
damaged or deleted, \textbf{expire\_backups} no longer knows the ages
of the backups and refuses to work. In this case you can use the
\code{-{-}reconstruct-state} option to try to reconstruct the state
from the backup dates. However, the accuracy of this reconstruction
depends strongly on how rigorous you have been with making backups (it
is only completely correct if the time between subsequent backups has
always been exactly the same), so it's generally a good idea not to
tamper with the state file.

For a full list of available options, run \textbf{expire\_backups.py
--help}.


\section{remove\_objects.py}
\label{contrib:remove-objects}\label{contrib:remove-objects-py}
\textbf{remove\_objects.py} is a program to remove a list of objects
from a storage backend. Since it acts on the backend-level, the
backend need not contain an S3QL file system.


\chapter{Tips \& Tricks}
\label{tips::doc}\label{tips:tips-tricks}

\section{SSH Backend}
\label{tips:ssh-tipp}\label{tips:ssh-backend}
By combining S3QL's local backend with \href{http://fuse.sourceforge.net/sshfs.html}{sshfs}, it is possible to store an
S3QL file system on arbitrary SSH servers: first mount the remote
target directory into the local filesystem,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{sshfs user@my.server.com:/mnt/s3ql /mnt/sshfs}
\end{Verbatim}

and then give the mountpoint to S3QL as a local destination:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{mount.s3ql local:///mnt/sshfs/myfsdata /mnt/s3ql}
\end{Verbatim}


\section{Permanently mounted backup file system}
\label{tips:permanently-mounted-backup-file-system}
If you use S3QL as a backup file system, it can be useful to mount the
file system permanently (rather than just mounting it for a backup and
unmounting it afterwards). Especially if your file system becomes
large, this saves you long mount- and unmount times if you only want
to restore a single file.

If you decide to do so, you should make sure to
\begin{itemize}
\item {} 
Use {\hyperref[special:s3qllock]{\emph{s3qllock}}} to ensure that backups are immutable
after they have been made.

\item {} 
Call {\hyperref[special:s3qlctrl]{\emph{s3qlctrl upload-meta}}} right after a every
backup to make sure that the newest metadata is stored safely (if
you do backups often enough, this may also allow you to set the
\code{-{-}metadata-upload-interval} option of \textbf{mount.s3ql}
to zero).

\end{itemize}


\section{Improving copy performance}
\label{tips:copy-performance}\label{tips:improving-copy-performance}
\begin{notice}{note}{Note:}
The following applies only when copying data \textbf{from} an S3QL file
system, \textbf{not} when copying data \textbf{to} an S3QL file system.
\end{notice}

If you want to copy a lot of smaller files \emph{from} an S3QL file system
(e.g. for a system restore) you will probably notice that the
performance is rather bad.

The reason for this is intrinsic to the way S3QL works. Whenever you
read a file, S3QL first has to retrieve this file over the network
from the backend. This takes a minimum amount of time (the network
latency), no matter how big or small the file is. So when you copy
lots of small files, 99\% of the time is actually spend waiting for
network data.

Theoretically, this problem is easy to solve: you just have to copy
several files at the same time. In practice, however, almost all unix
utilities (\code{cp}, \code{rsync}, \code{tar} and friends) insist on copying
data one file at a time. This makes a lot of sense when copying data
on the local hard disk, but in case of S3QL this is really
unfortunate.

The best workaround that has been found so far is to copy files by
starting several rsync processes at once and use exclusion rules to
make sure that they work on different sets of files.

For example, the following script will start 3 rsync instances. The
first instance handles all filenames starting with a-f, the second the
filenames from g-l and the third covers the rest. The \code{+ */} rule
ensures that every instance looks into all directories.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{}!/bin/bash}

\PYG{l}{RSYNC\PYGZus{}ARGS=\PYGZdq{}\PYGZhy{}aHv /mnt/s3ql/ /home/restore/\PYGZdq{}}

\PYG{l}{rsync \PYGZhy{}f \PYGZdq{}+ */\PYGZdq{} \PYGZhy{}f \PYGZdq{}\PYGZhy{}! }\PYG{g+ge}{[a\PYGZhy{}f]}\PYG{l}{*\PYGZdq{} \PYGZdl{}RSYNC\PYGZus{}ARGS \PYGZam{}}
\PYG{l}{rsync \PYGZhy{}f \PYGZdq{}+ */\PYGZdq{} \PYGZhy{}f \PYGZdq{}\PYGZhy{}! }\PYG{g+ge}{[g\PYGZhy{}l]}\PYG{l}{*\PYGZdq{} \PYGZdl{}RSYNC\PYGZus{}ARGS \PYGZam{}}
\PYG{l}{rsync \PYGZhy{}f \PYGZdq{}+ */\PYGZdq{} \PYGZhy{}f \PYGZdq{}\PYGZhy{} }\PYG{g+ge}{[a\PYGZhy{}l]}\PYG{l}{*\PYGZdq{} \PYGZdl{}RSYNC\PYGZus{}ARGS \PYGZam{}}

\PYG{l}{wait}
\end{Verbatim}

The optimum number of parallel processes depends on your network
connection and the size of the files that you want to transfer.
However, starting about 10 processes seems to be a good compromise
that increases performance dramatically in almost all situations.

S3QL comes with a script named \code{pcp.py} in the \code{contrib} directory
that can be used to transfer files in parallel without having to write
an explicit script first. See the description of {\hyperref[contrib:pcp]{\emph{pcp.py}}} for
details.


\chapter{Known Issues}
\label{issues::doc}\label{issues:known-issues}\begin{itemize}
\item {} 
S3QL de-duplicates data blocks based solely only on SHA256
checksums, without doing a byte-by-byte comparison of the blocks.
Since it is possible for two data blocks to have the same checksum
despite having different contents, this can lead to problems. If two
such blocks are stored in an S3QL file system, the data in one block
will be lost and replaced by the data in the other block. However,
the chances of this occuring for any two blocks are about 1 in 10\textasciicircum{}77
(2\textasciicircum{}256). For a file system that holds a total of 10\textasciicircum{}34 blocks, the
chances of a collision increase to about 1 in 10\textasciicircum{}9. Storing more
than 10\textasciicircum{}34 blocks (or about 10\textasciicircum{}25 TB with an (extremely small) block
size of 4 kB) is therefore not recommended. Being exceptionally
unlucky may also be a disadvantage.

\item {} 
S3QL does not support Access Control Lists (ACLs). This is due to a
bug in the FUSE library and will therefore hopefully be fixed at
some point. See \href{https://bitbucket.org/nikratio/s3ql/issue/16/support-access-control-lists-acls}{issue \#16}
for more details.

\item {} 
As of Linux kernel 3.5 S3QL file systems do not implement the ``write
protect'' bit on directories. In other words, even if a directory has
the write protect bit set, the owner of the directory can delete any
files and (empty) subdirectories inside it. This is a bug in the
FUSE kernel module
(cf. \href{https://github.com/libfuse/libfuse/issues/23}{https://github.com/libfuse/libfuse/issues/23}) and needs to be
fixed in the kernel.  Unfortunately it does not look as if this is
going to be fixed anytime soon (as of 2016/2/28).

\item {} 
S3QL is rather slow when an application tries to write data in
unreasonably small chunks. If a 1 MiB file is copied in chunks of 1
KB, this will take more than 10 times as long as when it's copied
with the (recommended) chunk size of 128 KiB.

This is a limitation of the FUSE library (which does not yet support
write caching) which will hopefully be addressed in some future FUSE
version.

Most applications, including e.g. GNU \code{cp} and \code{rsync}, use
reasonably large buffers and are therefore not affected by this
problem and perform very efficient on S3QL file systems.

However, if you encounter unexpectedly slow performance with a
specific program, this might be due to the program using very small
write buffers. Although this is not really a bug in the program,
it might be worth to ask the program's authors for help.

\item {} 
S3QL always updates file and directory access times as if the \code{relatime}
mount option has been specified: the access time (``atime'') is only updated
if it is currently earlier than either the status change time
(``ctime'') or modification time (``mtime'').

\item {} 
S3QL directories always have an \code{st\_nlink} value of 1. This may confuse
programs that rely on directories having \code{st\_nlink} values of \emph{(2 +
number of sub directories)}.

Note that this is not a bug in S3QL. Including sub directories in
the \code{st\_nlink} value is a Unix convention, but by no means a
requirement. If an application blindly relies on this convention
being followed, then this is a bug in the application.

A prominent example are early versions of GNU find, which required
the \code{-{-}noleaf} option to work correctly on S3QL file systems. This
bug has already been fixed in recent find versions.

\item {} 
The \code{umount} and \code{fusermount -u} commands will \emph{not} block until all
data has been uploaded to the backend. (this is a FUSE limitation
that will hopefully be removed in the future, see \href{https://bitbucket.org/nikratio/s3ql/issue/1/blocking-fusermount-and-umount}{issue \#1}). If
you use either command to unmount an S3QL file system, you have to
take care to explicitly wait for the \code{mount.s3ql} process to
terminate before you shut down or restart the system. Therefore it
is generally not a good idea to mount an S3QL file system in
\code{/etc/fstab} (you should use a dedicated init script instead).

\item {} 
S3QL relies on the backends not to run out of space. This is a given
for big storage providers like Amazon S3 or Google Storage, but you
may stumble upon this if you use your own server or smaller providers.

If there is no space left in the backend, attempts to write more
data into the S3QL file system will fail and the file system will be
in an inconsistent state and require a file system check (and you
should make sure to make space available in the backend before
running the check).

Unfortunately, there is no way to handle insufficient space in the
backend without leaving the file system inconsistent. Since
S3QL first writes data into the cache, it can no longer return an
error when it later turns out that the cache can not be committed to
the backend.

\item {} 
When using python-dugong versions 3.3 or earlier, S3QL supports only
CONNECT-style proxying, which may cause issues with some proxy
servers when using plain HTTP. Upgrading to python-dugong 3.4 or
newer removes this limitation.

\end{itemize}


\chapter{Manpages}
\label{man/index::doc}\label{man/index:manpages}
The man pages are installed with S3QL on your system and can be viewed
with the \textbf{man} command. For reference, they are also included
here in the User's Guide.


\section{The \textbf{mkfs.s3ql} command}
\label{man/mkfs::doc}\label{man/mkfs:the-command-command}

\subsection{Synopsis}
\label{man/mkfs:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{mkfs.s3ql }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/mkfs:description}
The \textbf{mkfs.s3ql} command creates a new file system in the location
specified by \emph{storage url}. The storage url depends on the backend
that is used. The S3QL User's Guide should be consulted for a
description of the available backends.

Unless you have specified the \code{-{-}plain} option, \code{mkfs.s3ql} will ask
you to enter an encryption password. This password will \emph{not} be read
from an authentication file specified with the \code{-{-}authfile}
option to prevent accidental creation of an encrypted file system.


\subsection{Options}
\label{man/mkfs:options}
The \textbf{mkfs.s3ql} command accepts the following options.
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}version]  
just print program version and exit
\item [-L \textless{}name\textgreater{}]  
Filesystem label
\item [-{-}max-obj-size \textless{}size\textgreater{}]  
Maximum size of storage objects in KiB. Files bigger
than this will be spread over multiple objects in the
storage backend. Default: 10240 KiB.
\item [-{-}plain]  
Create unencrypted file system.
\item [-{-}force]  
Overwrite any existing data.
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/mkfs:exit-codes}
\textbf{mkfs.s3ql} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\item[{3}] \leavevmode
Invalid backend option.

\item[{11}] \leavevmode
No such backend.

\item[{12}] \leavevmode
Authentication file has insecure permissions.

\item[{13}] \leavevmode
Unable to parse proxy settings.

\item[{14}] \leavevmode
Invalid credentials (Authentication failed).

\item[{15}] \leavevmode
No permission to access backend (Authorization denied).

\item[{16}] \leavevmode
Invalid storage URL, specified location does not exist in backend.

\item[{19}] \leavevmode
Unable to connect to backend, can't resolve hostname.

\item[{45}] \leavevmode
Unable to access cache directory.

\end{description}\end{quote}


\subsection{See Also}
\label{man/mkfs:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{s3qladm} command}
\label{man/adm::doc}\label{man/adm:the-command-command}

\subsection{Synopsis}
\label{man/adm:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qladm }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}action\PYGZgt{}}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}

where \code{action} may be either of \textbf{passphrase},
\textbf{upgrade}, \textbf{delete} or \textbf{download-metadata}.


\subsection{Description}
\label{man/adm:description}
The \textbf{s3qladm} command performs various operations on \emph{unmounted} S3QL
file systems. The file system \emph{must not be mounted} when using
\textbf{s3qladm} or things will go wrong badly.

The storage url depends on the backend that is used. The S3QL User's
Guide should be consulted for a description of the available backends.


\subsection{Options}
\label{man/adm:options}
The \textbf{s3qladm} command accepts the following options.
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}log \textless{}target\textgreater{}]  
Destination for log messages. Specify \code{none} for
standard output or \code{syslog} for the system logging
daemon. Anything else will be interpreted as a file
name. Log files will be rotated when they reach 1 MiB,
and at most 5 old log files will be kept. Default:
\code{None}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}version]  
just print program version and exit
\end{optionlist}
\end{quote}

Hint: run \code{s3qladm \textless{}action\textgreater{} -{-}help} to get help on the additional arguments
that the different actions take.


\subsection{Actions}
\label{man/adm:actions}
The following actions may be specified:
\begin{description}
\item[{passphrase}] \leavevmode
Changes the encryption passphrase of the file system.

\item[{upgrade}] \leavevmode
Upgrade the file system to the newest revision.

\item[{delete}] \leavevmode
Delete the file system with all the stored data.

\item[{download-metadata}] \leavevmode
Interactively download backups of the file system metadata.

\end{description}


\subsection{Exit Codes}
\label{man/adm:exit-codes}
\textbf{s3qladm} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\item[{3}] \leavevmode
Invalid backend option.

\item[{10}] \leavevmode
Could not open log file for writing.

\item[{11}] \leavevmode
No such backend.

\item[{12}] \leavevmode
Authentication file has insecure permissions.

\item[{13}] \leavevmode
Unable to parse proxy settings.

\item[{14}] \leavevmode
Invalid credentials (Authentication failed).

\item[{15}] \leavevmode
No permission to access backend (Authorization denied).

\item[{16}] \leavevmode
Invalid storage URL, specified location does not exist in backend.

\item[{17}] \leavevmode
Wrong file system passphrase.

\item[{18}] \leavevmode
No S3QL file system found at given storage URL.

\item[{19}] \leavevmode
Unable to connect to backend, can't resolve hostname.

\item[{45}] \leavevmode
Unable to access cache directory.

\end{description}\end{quote}


\subsection{See Also}
\label{man/adm:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{mount.s3ql} command}
\label{man/mount::doc}\label{man/mount:the-command-command}

\subsection{Synopsis}
\label{man/mount:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{mount.s3ql }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}mount point\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/mount:description}
The \textbf{mount.s3ql} command mounts the S3QL file system stored in \emph{storage
url} in the directory \emph{mount point}. The storage url depends on the
backend that is used. The S3QL User's Guide should be consulted for a
description of the available backends.


\subsection{Options}
\label{man/mount:options}
The \textbf{mount.s3ql} command accepts the following options.
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}log \textless{}target\textgreater{}]  
Destination for log messages. Specify \code{none} for
standard output or \code{syslog} for the system logging
daemon. Anything else will be interpreted as a file
name. Log files will be rotated when they reach 1 MiB,
and at most 5 old log files will be kept. Default:
\code{\textasciitilde{}/.s3ql/mount.log}
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}version]  
just print program version and exit
\item [-{-}cachesize \textless{}size\textgreater{}]  
Cache size in KiB (default: autodetect).
\item [-{-}max-cache-entries \textless{}num\textgreater{}]  
Maximum number of entries in cache (default:
autodetect). Each cache entry requires one file
descriptor, so if you increase this number you have to
make sure that your process file descriptor limit (as
set with \code{ulimit -n}) is high enough (at least the
number of cache entries + 100).
\item [-{-}allow-other]  
Normally, only the user who called \code{mount.s3ql} can
access the mount point. This user then also has full
access to it, independent of individual file
permissions. If the \code{-{-}allow-other} option is
specified, other users can access the mount point as
well and individual file permissions are taken into
account for all users.
\item [-{-}allow-root]  
Like \code{-{-}allow-other}, but restrict access to the
mounting user and the root user.
\item [-{-}fg]  
Do not daemonize, stay in foreground
\item [-{-}upstart]  
Stay in foreground and raise SIGSTOP once mountpoint
is up.
\item [-{-}compress \textless{}algorithm-lvl\textgreater{}]  
Compression algorithm and compression level to use
when storing new data. \emph{algorithm} may be any of
\code{lzma}, \code{bzip2}, \code{zlib}, or none. \emph{lvl} may be any
integer from 0 (fastest) to 9 (slowest). Default:
\code{lzma-6}
\item [-{-}metadata-upload-interval \textless{}seconds\textgreater{}]  
Interval in seconds between complete metadata uploads.
Set to 0 to disable. Default: 24h.
\item [-{-}threads \textless{}no\textgreater{}]  
Number of parallel upload threads to use (default:
auto).
\item [-{-}nfs]  
Enable some optimizations for exporting the file
system over NFS. (default: False)
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/mount:exit-codes}
\textbf{mount.s3ql} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\item[{3}] \leavevmode
Invalid backend option.

\item[{10}] \leavevmode
Could not open log file for writing.

\item[{11}] \leavevmode
No such backend.

\item[{12}] \leavevmode
Authentication file has insecure permissions.

\item[{13}] \leavevmode
Unable to parse proxy settings.

\item[{14}] \leavevmode
Invalid credentials (Authentication failed).

\item[{15}] \leavevmode
No permission to access backend (Authorization denied).

\item[{16}] \leavevmode
Invalid storage URL, specified location does not exist in backend.

\item[{17}] \leavevmode
Wrong file system passphrase.

\item[{18}] \leavevmode
No S3QL file system found at given storage URL.

\item[{19}] \leavevmode
Unable to connect to backend, can't resolve hostname.

\item[{30}] \leavevmode
File system was not unmounted cleanly.

\item[{31}] \leavevmode
File system appears to be mounted elsewhere.

\item[{32}] \leavevmode
Unsupported file system revision (too old).

\item[{33}] \leavevmode
Unsupported file system revision (too new).

\item[{34}] \leavevmode
Insufficient free nodes, need to run \textbf{fsck.s3ql}.

\item[{35}] \leavevmode
Attempted to mount read-only, this is not supported.

\item[{36}] \leavevmode
Mountpoint does not exist.

\item[{37}] \leavevmode
Not enough available file descriptors.

\item[{39}] \leavevmode
Unable to bind file system to mountpoint.

\item[{45}] \leavevmode
Unable to access cache directory.

\end{description}\end{quote}


\subsection{See Also}
\label{man/mount:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{s3qlstat} command}
\label{man/stat::doc}\label{man/stat:the-command-command}

\subsection{Synopsis}
\label{man/stat:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qlstat }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}mountpoint\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/stat:description}
The \textbf{s3qlstat} command prints statistics about the S3QL file system mounted
at \code{mountpoint}.

\textbf{s3qlstat} can only be called by the user that mounted the file system
and (if the file system was mounted with \code{-{-}allow-other} or
\code{-{-}allow-root}) the root user.


\subsection{Options}
\label{man/stat:options}
The \textbf{s3qlstat} command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\item [-{-}raw]  
Do not pretty-print numbers
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/stat:exit-codes}
\textbf{s3qlstat} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\end{description}\end{quote}


\subsection{See Also}
\label{man/stat:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{s3qlctrl} command}
\label{man/ctrl::doc}\label{man/ctrl:the-command-command}

\subsection{Synopsis}
\label{man/ctrl:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qlctrl }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}action\PYGZgt{}}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}mountpoint\PYGZgt{}}\PYG{l}{ ...}
\end{Verbatim}

where \code{action} may be either of \textbf{flushcache},
\textbf{upload-meta}, \textbf{cachesize} or
\textbf{log-metadata}.


\subsection{Description}
\label{man/ctrl:description}
The \textbf{s3qlctrl} command performs various actions on the S3QL file system mounted
in \code{mountpoint}.

\textbf{s3qlctrl} can only be called by the user that mounted the file system
and (if the file system was mounted with \code{-{-}allow-other} or
\code{-{-}allow-root}) the root user.

The following actions may be specified:
\begin{description}
\item[{flushcache}] \leavevmode
Uploads all changed file data to the backend.

\item[{upload-meta}] \leavevmode
Upload metadata to the backend. All file system operations will
block while a snapshot of the metadata is prepared for upload.

\item[{cachesize}] \leavevmode
Changes the cache size of the file system. This action requires an
additional argument that specifies the new cache size in KiB, so the
complete command line is:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qlctrl }\PYG{g+ge}{[options]}\PYG{l}{ cachesize }\PYG{n+nv}{\PYGZlt{}mountpoint\PYGZgt{}}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}new\PYGZhy{}cache\PYGZhy{}size\PYGZgt{}}
\end{Verbatim}

\item[{log}] \leavevmode
Change the amount of information that is logged into
\code{\textasciitilde{}/.s3ql/mount.log} file. The complete syntax is:

\begin{Verbatim}[commandchars=\\\{\}]
s3qlctrl [options] log \PYGZlt{}mountpoint\PYGZgt{} \PYGZlt{}level\PYGZgt{} [\PYGZlt{}module\PYGZgt{} [\PYGZlt{}module\PYGZgt{} ...]]
\end{Verbatim}

here \code{level} is the desired new log level and may be either of
\emph{debug}, \emph{info} or \emph{warn}. One or more \code{module} may only be
specified with the \emph{debug} level and allow to restrict the debug
output to just the listed modules.

\end{description}


\subsection{Options}
\label{man/ctrl:options}
The \textbf{s3qlctrl} command also accepts the following options, no matter
what specific action is being invoked:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\end{optionlist}
\end{quote}

Hint: run \code{s3qlctrl \textless{}action\textgreater{} -{-}help} to get help on the additional arguments
that the different actions take.


\subsection{Exit Codes}
\label{man/ctrl:exit-codes}
\textbf{s3qlctrl} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\end{description}\end{quote}


\subsection{See Also}
\label{man/ctrl:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{s3qlcp} command}
\label{man/cp::doc}\label{man/cp:the-command-command}

\subsection{Synopsis}
\label{man/cp:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qlcp }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}source\PYGZhy{}dir\PYGZgt{}}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}dest\PYGZhy{}dir\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/cp:description}
The \textbf{s3qlcp} command duplicates the directory tree \code{source-dir}
into \code{dest-dir} without physically copying the file contents.
Both source and destination must lie inside the same S3QL file system.

The replication will not take any additional space. Only if one of
directories is modified later on, the modified data will take
additional storage space.

\code{s3qlcp} can only be called by the user that mounted the file system
and (if the file system was mounted with \code{-{-}allow-other} or \code{-{-}allow-root})
the root user.

Note that:
\begin{itemize}
\item {} 
After the replication, both source and target directory will still
be completely ordinary directories. You can regard \code{\textless{}src\textgreater{}} as a
snapshot of \code{\textless{}target\textgreater{}} or vice versa. However, the most common
usage of \code{s3qlcp} is to regularly duplicate the same source
directory, say \code{documents}, to different target directories. For a
e.g. monthly replication, the target directories would typically be
named something like \code{documents\_January} for the replication in
January, \code{documents\_February} for the replication in February etc.
In this case it is clear that the target directories should be
regarded as snapshots of the source directory.

\item {} 
Exactly the same effect could be achieved by an ordinary copy
program like \code{cp -a}. However, this procedure would be orders of
magnitude slower, because \code{cp} would have to read every file
completely (so that S3QL had to fetch all the data over the network
from the backend) before writing them into the destination folder.

\end{itemize}


\subsubsection{Snapshotting vs Hardlinking}
\label{man/cp:snapshotting-vs-hardlinking}
Snapshot support in S3QL is inspired by the hardlinking feature that
is offered by programs like \href{http://www.samba.org/rsync}{rsync} or
\href{http://savannah.nongnu.org/projects/storebackup}{storeBackup}.
These programs can create a hardlink instead of copying a file if an
identical file already exists in the backup. However, using hardlinks
has two large disadvantages:
\begin{itemize}
\item {} 
backups and restores always have to be made with a special program
that takes care of the hardlinking. The backup must not be touched
by any other programs (they may make changes that inadvertently
affect other hardlinked files)

\item {} 
special care needs to be taken to handle files which are already
hardlinked (the restore program needs to know that the hardlink was
not just introduced by the backup program to safe space)

\end{itemize}

S3QL snapshots do not have these problems, and they can be used with
any backup program.


\subsection{Options}
\label{man/cp:options}
The \textbf{s3qlcp} command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/cp:exit-codes}
\textbf{s3qlcp} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\end{description}\end{quote}


\subsection{See Also}
\label{man/cp:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{s3qlrm} command}
\label{man/rm::doc}\label{man/rm:the-command-command}

\subsection{Synopsis}
\label{man/rm:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qlrm }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}directory\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/rm:description}
The \textbf{s3qlrm} command recursively deletes files and directories on an
S3QL file system. Although \textbf{s3qlrm} is faster than using e.g.
\textbf{rm -r{}`}, the main reason for its existence is that it allows
you to delete immutable trees (which can be created with
\textbf{s3qllock}) as well.

Be warned that there is no additional confirmation. The directory will
be removed entirely and immediately.

\textbf{s3qlrm} can only be called by the user that mounted the file system
and (if the file system was mounted with \code{-{-}allow-other} or
\code{-{-}allow-root}) the root user.


\subsection{Options}
\label{man/rm:options}
The \textbf{s3qlrm} command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/rm:exit-codes}
\textbf{s3qlrm} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\end{description}\end{quote}


\subsection{See Also}
\label{man/rm:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{s3qllock} command}
\label{man/lock::doc}\label{man/lock:the-command-command}

\subsection{Synopsis}
\label{man/lock:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3qllock }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}directory\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/lock:description}
The \textbf{s3qllock} command makes a directory tree in an S3QL file
system immutable. Immutable trees can no longer be changed in any way
whatsoever. You can not add new files or directories and you can not
change or delete existing files and directories. The only way to get
rid of an immutable tree is to use the \textbf{s3qlrm} command.

\textbf{s3qllock} can only be called by the user that mounted the file system
and (if the file system was mounted with \code{-{-}allow-other} or
\code{-{-}allow-root}) the root user.


\subsection{Rationale}
\label{man/lock:rationale}
Immutability is a feature designed for backups. Traditionally, backups
have been made on external tape drives. Once a backup was made, the
tape drive was removed and locked somewhere in a shelf. This has the
great advantage that the contents of the backup are now permanently
fixed. Nothing (short of physical destruction) can change or delete
files in the backup.

In contrast, when backing up into an online storage system like S3QL,
all backups are available every time the file system is mounted.
Nothing prevents a file in an old backup from being changed again
later on. In the worst case, this may make your entire backup system
worthless. Imagine that your system gets infected by a nasty virus
that simply deletes all files it can find -- if the virus is active
while the backup file system is mounted, the virus will destroy all
your old backups as well!

Even if the possibility of a malicious virus or trojan horse is
excluded, being able to change a backup after it has been made is
generally not a good idea. A common S3QL use case is to keep the file
system mounted at all times and periodically create backups with
\textbf{rsync -a}. This allows every user to recover her files from a
backup without having to call the system administrator. However, this
also allows every user to accidentally change or delete files \emph{in} one
of the old backups.

Making a backup immutable protects you against all these problems.
Unless you happen to run into a virus that was specifically programmed
to attack S3QL file systems, backups can be neither deleted nor
changed after they have been made immutable.


\subsection{Options}
\label{man/lock:options}
The \textbf{s3qllock} command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/lock:exit-codes}
\textbf{s3qllock} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\end{description}\end{quote}


\subsection{See Also}
\label{man/lock:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{umount.s3ql} command}
\label{man/umount::doc}\label{man/umount:the-command-command}

\subsection{Synopsis}
\label{man/umount:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{umount.s3ql }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}mount point\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/umount:description}
The \textbf{umount.s3ql} command unmounts the S3QL file system mounted in the
directory \emph{mount point} and blocks until all data has been uploaded to
the storage backend.

Only the user who mounted the file system with \textbf{mount.s3ql}
is able to unmount it with \textbf{umount.s3ql}. If you are root and want to
unmount an S3QL file system mounted by an ordinary user, you have to
use the \textbf{fusermount -u} or \textbf{umount} command instead.
Note that these commands do not block until all data has been
uploaded, so if you use them instead of \textbf{umount.s3ql} then
you should manually wait for the \textbf{mount.s3ql} process to
terminate before shutting down the system.


\subsection{Options}
\label{man/umount:options}
The \textbf{umount.s3ql} command accepts the following options.
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\item [-{-}lazy, -z]  
Lazy umount. Detaches the file system immediately,
even if there are still open files. The data will be
uploaded in the background once all open files have
been closed.
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/umount:exit-codes}
\textbf{umount.s3ql} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\end{description}\end{quote}


\subsection{See Also}
\label{man/umount:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{fsck.s3ql} command}
\label{man/fsck::doc}\label{man/fsck:the-command-command}

\subsection{Synopsis}
\label{man/fsck:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{fsck.s3ql }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/fsck:description}
The \textbf{fsck.s3ql} command checks the file system in the location specified
by \emph{storage url} for errors and attempts to repair any problems. The
storage url depends on the backend that is used. The S3QL User's Guide
should be consulted for a description of the available backends.


\subsection{Options}
\label{man/fsck:options}
The \textbf{fsck.s3ql} command accepts the following options.
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}log \textless{}target\textgreater{}]  
Destination for log messages. Specify \code{none} for
standard output or \code{syslog} for the system logging
daemon. Anything else will be interpreted as a file
name. Log files will be rotated when they reach 1 MiB,
and at most 5 old log files will be kept. Default:
\code{\textasciitilde{}/.s3ql/fsck.log}
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}version]  
just print program version and exit
\item [-{-}batch]  
If user input is required, exit without prompting.
\item [-{-}force]  
Force checking even if file system is marked clean.
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/fsck:exit-codes}
If \textbf{fsck.s3ql} found any file system errors (no matter if they were
corrected or not), the exit code will be 128 plus one of the codes
listed below. If no errors were found, the following exit codes are
used as-is:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\item[{3}] \leavevmode
Invalid backend option.

\item[{10}] \leavevmode
Could not open log file for writing.

\item[{11}] \leavevmode
No such backend.

\item[{12}] \leavevmode
Authentication file has insecure permissions.

\item[{13}] \leavevmode
Unable to parse proxy settings.

\item[{14}] \leavevmode
Invalid credentials (Authentication failed).

\item[{15}] \leavevmode
No permission to access backend (Authorization denied).

\item[{16}] \leavevmode
Invalid storage URL, specified location does not exist in backend.

\item[{17}] \leavevmode
Wrong file system passphrase.

\item[{18}] \leavevmode
No S3QL file system found at given storage URL.

\item[{19}] \leavevmode
Unable to connect to backend, can't resolve hostname.

\item[{32}] \leavevmode
Unsupported file system revision (too old).

\item[{33}] \leavevmode
Unsupported file system revision (too new).

\item[{40}] \leavevmode
Cannot check mounted file system.

\item[{41}] \leavevmode
User input required, but running in batch mode.

\item[{42}] \leavevmode
File system check aborted by user.

\item[{43}] \leavevmode
Local metadata is corrupted.

\item[{44}] \leavevmode
Uncorrectable errors found.

\item[{45}] \leavevmode
Unable to access cache directory.

\item[{128}] \leavevmode
This error code will be \emph{added} to one of the codes above if any
file system errors have been found (no matter if they were
corrected or not).

\end{description}\end{quote}


\subsection{See Also}
\label{man/fsck:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{s3ql\_oauth\_client} command}
\label{man/oauth_client::doc}\label{man/oauth_client:the-command-command}\label{man/oauth_client:oauth-client}

\subsection{Synopsis}
\label{man/oauth_client:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3ql\PYGZus{}oauth\PYGZus{}client }\PYG{g+ge}{[options]}
\end{Verbatim}


\subsection{Description}
\label{man/oauth_client:description}
The \textbf{s3ql\_oauth\_client} command may be used to obtain OAuth2 authentication
tokens for use with Google Storage. It requests ``user code'' from
Google which has to be pasted into the browser to complete the
authentication process interactively. Once authentication in the
browser has been completed, \textbf{s3ql\_oauth\_client} displays the OAuth2 refresh
token.

When combined with the special username \code{oauth2}, the refresh token
can be used as a backend passphrase when using the Google Storage S3QL
backend.


\subsection{Options}
\label{man/oauth_client:options}
The \textbf{s3ql\_oauth\_client} command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/oauth_client:exit-codes}
\textbf{s3ql\_oauth\_client} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\end{description}\end{quote}


\subsection{See Also}
\label{man/oauth_client:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{s3ql\_verify} command}
\label{man/verify::doc}\label{man/verify:the-command-command}

\subsection{Synopsis}
\label{man/verify:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{s3ql\PYGZus{}verify }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}storage url\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/verify:description}
The \textbf{s3ql\_verify} command verifies all data in the file system.  In
contrast to \textbf{fsck.s3ql}, \textbf{s3ql\_verify} does not trust the object
listing returned by the backend, but actually attempts to retrieve
every object. It therefore takes a lot longer.

The format of \code{\textless{}storage url\textgreater{}} depends on the backend that is
used. The S3QL User's Guide should be consulted for a description of
the available backends.


\subsection{Options}
\label{man/verify:options}
The \textbf{s3ql\_verify} command accepts the following options.
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}quiet]  
be really quiet
\item [-{-}version]  
just print program version and exit
\item [-{-}cachedir \textless{}path\textgreater{}]  
Store cached data in this directory (default:
\code{\textasciitilde{}/.s3ql)}
\item [-{-}authfile \textless{}path\textgreater{}]  
Read authentication credentials from this file
(default: \code{\textasciitilde{}/.s3ql/authinfo2)}
\item [-{-}backend-options \textless{}options\textgreater{}]  
Backend specific options (separate by commas). See
backend documentation for available options.
\item [-{-}missing-file \textless{}name\textgreater{}]  
File to store keys of missing objects.
\item [-{-}corrupted-file \textless{}name\textgreater{}]  
File to store keys of corrupted objects.
\item [-{-}data]  
Read every object completely, instead of checking just
the metadata.
\item [-{-}parallel PARALLEL]  
Number of connections to use in parallel.
\item [-{-}start-with \textless{}n\textgreater{}]  
Skip over first \textless{}n\textgreater{} objects and with verifying object
\textless{}n\textgreater{}+1.
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/verify:exit-codes}
\textbf{s3ql\_verify} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\item[{3}] \leavevmode
Invalid backend option.

\item[{10}] \leavevmode
Could not open log file for writing.

\item[{11}] \leavevmode
No such backend.

\item[{12}] \leavevmode
Authentication file has insecure permissions.

\item[{13}] \leavevmode
Unable to parse proxy settings.

\item[{14}] \leavevmode
Invalid credentials (Authentication failed).

\item[{15}] \leavevmode
No permission to access backend (Authorization denied).

\item[{16}] \leavevmode
Invalid storage URL, specified location does not exist in backend.

\item[{17}] \leavevmode
Wrong file system passphrase.

\item[{18}] \leavevmode
No S3QL file system found at given storage URL.

\item[{19}] \leavevmode
Unable to connect to backend, can't resolve hostname.

\item[{32}] \leavevmode
Unsupported file system revision (too old).

\item[{33}] \leavevmode
Unsupported file system revision (too new).

\item[{45}] \leavevmode
Unable to access cache directory.

\item[{46}] \leavevmode
The file system data was verified, and some objects were found
to be missing or corrupted.

\end{description}\end{quote}


\subsection{See Also}
\label{man/verify:see-also}
The S3QL homepage is at \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.

The full S3QL documentation should also be installed somewhere on your
system, common locations are \code{/usr/share/doc/s3ql} or
\code{/usr/local/doc/s3ql}.


\section{The \textbf{pcp} command}
\label{man/pcp::doc}\label{man/pcp:the-command-command}

\subsection{Synopsis}
\label{man/pcp:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{pcp }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}source\PYGZgt{}}\PYG{l}{ }\PYG{g+ge}{[\PYGZlt{}source\PYGZgt{} ...]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}destination\PYGZgt{}}
\end{Verbatim}


\subsection{Description}
\label{man/pcp:description}
The \textbf{pcp} command is a is a wrapper that starts several
\textbf{sync} processes to copy directory trees in parallel. This is
allows much better copying performance on file system that have
relatively high latency when retrieving individual files like S3QL.

\textbf{Note}: Using this program only improves performance when copying
\emph{from} an S3QL file system. When copying \emph{to} an S3QL file system,
using \textbf{pcp} is more likely to \emph{decrease} performance.


\subsection{Options}
\label{man/pcp:options}
The \textbf{pcp} command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}quiet]  
be really quiet
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}version]  
just print program version and exit
\item [-a]  
Pass -aHAX option to rsync.
\item [-{-}processes \textless{}no\textgreater{}]  
Number of rsync processes to use (default: 10).
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/pcp:exit-codes}
\textbf{pcp} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\end{description}\end{quote}


\subsection{See Also}
\label{man/pcp:see-also}
\textbf{pcp} is shipped as part of S3QL, \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.


\section{The \textbf{expire\_backups} command}
\label{man/expire_backups::doc}\label{man/expire_backups:the-command-command}

\subsection{Synopsis}
\label{man/expire_backups:synopsis}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{expire\PYGZus{}backups }\PYG{g+ge}{[options]}\PYG{l}{ }\PYG{n+nv}{\PYGZlt{}age\PYGZgt{}}\PYG{l}{ }\PYG{g+ge}{[\PYGZlt{}age\PYGZgt{} ...]}
\end{Verbatim}


\subsection{Description}
\label{man/expire_backups:description}
The \textbf{expire\_backups} command intelligently remove old backups that are no
longer needed.

To define what backups you want to keep for how long, you define a
number of \emph{age ranges}. \textbf{expire\_backups} ensures that you
will have at least one backup in each age range at all times. It will
keep exactly as many backups as are required for that and delete any
backups that become redundant.

Age ranges are specified by giving a list of range boundaries in terms
of backup cycles. Every time you create a new backup, the existing
backups age by one cycle.

Example: when \textbf{expire\_backups} is called with the age range
definition \code{1 3 7 14 31}, it will guarantee that you always have the
following backups available:
\begin{enumerate}
\item {} 
A backup that is 0 to 1 cycles old (i.e, the most recent backup)

\item {} 
A backup that is 1 to 3 cycles old

\item {} 
A backup that is 3 to 7 cycles old

\item {} 
A backup that is 7 to 14 cycles old

\item {} 
A backup that is 14 to 31 cycles old

\end{enumerate}

\begin{notice}{note}{Note:}
If you do backups in fixed intervals, then one cycle will be
equivalent to the backup interval. The advantage of specifying the
age ranges in terms of backup cycles rather than days or weeks is
that it allows you to gracefully handle irregular backup intervals.
Imagine that for some reason you do not turn on your computer for
one month. Now all your backups are at least a month old, and if you
had specified the above backup strategy in terms of absolute ages,
they would all be deleted! Specifying age ranges in terms of backup
cycles avoids these sort of problems.
\end{notice}

\textbf{expire\_backups} usage is simple. It requires backups to be
stored in directories of the form \code{year-month-day\_hour:minute:seconds}
(\code{YYYY-MM-DD\_HH:mm:ss}) and works on all backups in the current
directory. So for the above backup strategy, the correct invocation
would be:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{l}{expire\PYGZus{}backups.py 1 3 7 14 31}
\end{Verbatim}

When storing your backups on an S3QL file system, you probably want to
specify the \code{-{-}use-s3qlrm} option as well. This tells
\textbf{expire\_backups} to use the {\hyperref[special:s3qlrm]{\emph{s3qlrm}}} command to
delete directories.

\textbf{expire\_backups} uses a ``state file'' to keep track which
backups are how many cycles old (since this cannot be inferred from
the dates contained in the directory names). The standard name for
this state file is \code{.expire\_backups.dat}. If this file gets
damaged or deleted, \textbf{expire\_backups} no longer knows the ages
of the backups and refuses to work. In this case you can use the
\code{-{-}reconstruct-state} option to try to reconstruct the state
from the backup dates. However, the accuracy of this reconstruction
depends strongly on how rigorous you have been with making backups (it
is only completely correct if the time between subsequent backups has
always been exactly the same), so it's generally a good idea not to
tamper with the state file.


\subsection{Options}
\label{man/expire_backups:options}
The \textbf{expire\_backups} command accepts the following options:
\begin{quote}
\begin{optionlist}{3cm}
\item [-{-}quiet]  
be really quiet
\item [-{-}debug-modules \textless{}modules\textgreater{}]  
Activate debugging output from specified modules (use
commas to separate multiple modules). Debug messages
will be written to the target specified by the
\code{-{-}log} option.
\item [-{-}debug]  
Activate debugging output from all S3QL modules. Debug
messages will be written to the target specified by
the \code{-{-}log} option.
\item [-{-}version]  
just print program version and exit
\item [-{-}state \textless{}file\textgreater{}]  
File to save state information in (default:
''.expire\_backups.dat'')
\item [-n]  
Dry run. Just show which backups would be deleted.
\item [-{-}reconstruct-state]  
Try to reconstruct a missing state file from backup
dates.
\item [-{-}use-s3qlrm]  
Use \code{s3qlrm} command to delete backups.
\end{optionlist}
\end{quote}


\subsection{Exit Codes}
\label{man/expire_backups:exit-codes}
\textbf{expire\_backups} may terminate with the following exit codes:
\begin{quote}\begin{description}
\item[{0}] \leavevmode
Everything went well.

\item[{1}] \leavevmode
An unexpected error occured. This may indicate a bug in the
program.

\item[{2}] \leavevmode
Invalid command line argument.

\end{description}\end{quote}


\subsection{See Also}
\label{man/expire_backups:see-also}
\textbf{expire\_backups} is shipped as part of S3QL, \href{https://bitbucket.org/nikratio/s3ql/}{https://bitbucket.org/nikratio/s3ql/}.


\chapter{Further Resources / Getting Help}
\label{resources::doc}\label{resources:resources}\label{resources:further-resources-getting-help}
If you have questions or problems with S3QL that you weren't able to
resolve with this manual, you might want to consider the following other resources:
\begin{itemize}
\item {} 
The \href{https://bitbucket.org/nikratio/s3ql/wiki}{S3QL Wiki}

\item {} 
The \href{https://bitbucket.org/nikratio/s3ql/wiki/FAQ}{S3QL FAQ}

\item {} 
The \href{http://groups.google.com/group/s3ql}{S3QL Mailing List}. You
can subscribe by sending a mail to
\href{mailto:s3ql+subscribe@googlegroups.com}{s3ql+subscribe@googlegroups.com}.

\end{itemize}

Please report any bugs you may encounter in the \href{https://bitbucket.org/nikratio/s3ql/issues}{Issue Tracker}.


\chapter{Implementation Details}
\label{impl_details::doc}\label{impl_details:impl-details}\label{impl_details:implementation-details}
This section provides some background information on how S3QL works
internally. Reading this section is not necessary to use S3QL.


\section{Metadata Storage}
\label{impl_details:metadata-storage}
Like most unix filesystems, S3QL has a concept of inodes.

The contents of directory inodes (aka the names and inodes of the
files and sub directories contained in a directory) are stored
directly in an \href{http://www.sqlite.org/}{SQLite} database. This database
is stored in a special storage object that is downloaded when the file
system is mounted and uploaded periodically in the background and when
the file system is unmounted. This has two implications:
\begin{enumerate}
\item {} 
The entire file system tree can be read from the
database. Fetching/storing storage objects from/in the storage
backend is only required to access the contents of files (or, more
precisely, inodes). This makes most file system operations very
fast because no data has to be send over the network.

\item {} 
An S3QL filesystem can only be mounted on one computer at a time,
using a single \textbf{mount.s3ql} process. Otherwise changes made in
one mountpoint will invariably be overwritten when the second mount
point is unmounted.

\end{enumerate}

Sockets, FIFOs and character devices do not need any additional
storage, all information about them is contained in the database.


\section{Data Storage}
\label{impl_details:data-storage}
The contents of file inodes are split into individual blocks. The
maximum size of a block is specified when the file system is created
and cannot be changed afterwards. Every block is stored as an
individual object in the backend, and the mapping from inodes to
blocks and from blocks to objects is stored in the database.

While the file system is mounted, blocks are cached locally.

Blocks can also be compressed and encrypted before they are stored in
the storage backend.

If some files have blocks with identical contents, the blocks will be
stored in the same backend object (i.e., the data is only stored
once).


\section{Data De-Duplication}
\label{impl_details:data-de-duplication}
Instead of uploading every block, S3QL first computes a checksum (a
SHA256 hash) to check if an identical blocks has already been stored
in an backend object. If that is the case, the new block will be
linked to the existing object instead of being uploaded.

This procedure is invisible for the user and the contents of the block
can still be changed. If several blocks share a backend object and one
of the blocks is changed, the changed block is automatically stored in
a new object (so that the contents of the other block remain
unchanged).


\section{Caching}
\label{impl_details:caching}
When an application tries to read or write from a file, S3QL
determines the block that contains the required part of the file and
retrieves it from the backend or creates it if it does not yet exist.
The block is then held in the cache directory. It is committed to S3
when it has not been accessed for more than a few seconds. Blocks are
removed from the cache only when the maximum cache size is reached.

When the file system is unmounted, all modified blocks are written to
the backend and the cache is cleaned.


\section{Eventual Consistency Handling}
\label{impl_details:eventual-consistency-handling}
S3QL has to take into account that with some storage providers,
changes in objects do not propagate immediately. For example, when an
Amazon S3 object is uploaded and immediately downloaded again, the
downloaded data might not yet reflect the changes done in the upload
(see also
\href{http://developer.amazonwebservices.com/connect/message.jspa?messageID=38538}{http://developer.amazonwebservices.com/connect/message.jspa?messageID=38538})

For the data blocks this is not a problem because a data blocks always
get a new object ID when they are updated.

For the metadata however, S3QL has to make sure that it always
downloads the most recent copy of the database when mounting the file
system.

To that end, metadata versions are numbered, and the most recent
version number is stored as part of the object id of a very small
``marker'' object. When S3QL has downloaded the metadata it checks the
version number against the marker object and, if the two do not agree,
waits for the most recent metadata to become available. Once the
current metadata is available, the version number is increased and the
marker object updated.


\section{Encryption}
\label{impl_details:encryption}
When the file system is created, \textbf{mkfs.s3ql} generates a 256 bit
master key by reading from \code{/dev/random}. The master key is
encrypted with the passphrase that is entered by the user, and then
stored with the rest of the file system data. Since the passphrase is
only used to access the master key (which is used to encrypt the
actual file system data), the passphrase can easily be changed.

Data is encrypted with a new session key for each object and each
upload. The session key is generated by appending a nonce to the
master key and then calculating the SHA256 hash. The nonce is
generated by concatenating the object id and the current UTC time as a
32 bit float. The precision of the time is given by the Python \href{http://docs.python.org/library/time.html\#time.time}{time()} function and
usually at least 1 millisecond. The SHA256 implementation is included
in the Python standard library.

Once the session key has been calculated, a SHA256 HMAC is calculated
over the data that is to be uploaded. Afterwards, the data is
compressed (unless \code{-{-}compress none} was passed to
\textbf{mount.s3ql}) and the HMAC inserted at the beginning. Both HMAC
and compressed data are then encrypted using 256 bit AES in CTR
mode using \href{http://www.pycrypto.org/}{PyCrypto}.  Finally, the nonce is
inserted in front of the encrypted data and HMAC, and the packet is
send to the backend as a new S3 object.



\renewcommand{\indexname}{Index}
\printindex
\end{document}
